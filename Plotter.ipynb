{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import localSettings as ls\n",
    "print(ls.main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1560556807118,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "6qsD0G-yYJ9K",
    "outputId": "5d52a3ec-50be-44fc-da44-3c0593e98bc6"
   },
   "outputs": [],
   "source": [
    "main_path = ls.main_path\n",
    "sys.path.append(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHRCALIBFACTOR = 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGqTJ5JgaDsx"
   },
   "outputs": [],
   "source": [
    "import plotter\n",
    "import importlib\n",
    "importlib.reload(plotter)\n",
    "import uproot\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import nue_booster \n",
    "importlib.reload(nue_booster)\n",
    "\n",
    "params = {\n",
    "    'axes.labelsize': 'x-large',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'ytick.labelsize': 'x-large'\n",
    "}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "\n",
    "import awkward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwoCIaigYJ9N"
   },
   "outputs": [],
   "source": [
    "fold = \"nuselection\"\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "\n",
    "mc = uproot.open(ls.ntuple_path+\"prodgenie_bnb_nu_uboone_overlay_mcc9.1_run3_G_reco2.root\")[fold][tree]\n",
    "#nc = uproot.open(ls.ntuple_path+\"prodgenie_nc_pi0_uboone_overlay-v08_00_00_16_run1_reco2.root\")[fold][tree]\n",
    "nue = uproot.open(ls.ntuple_path+\"prodgenie_bnb_intrinsic_nue_uboone_overlay_mcc9.1_run3_G_reco2.root\")[fold][tree]\n",
    "data = uproot.open(ls.ntuple_path+\"data_bnb_optfilter_G1_1e19_mcc9.1_reco2.root\")[fold][tree]\n",
    "ext = uproot.open(ls.ntuple_path+\"data_extbnb_mcc9.1_v08_00_00_16_18_run3_G_reco2.root\")[fold][tree]\n",
    "dirt = uproot.open(ls.ntuple_path+\"prodgenie_bnb_dirt_overlay_run3_mcc9.1_v08_00_00_18_G_reco2.root\")[fold][tree]\n",
    "lee = uproot.open(ls.ntuple_path+\"prodgenie_bnb_intrinsic_nue_uboone_overlay_mcc9.1_run3_G_reco2.root\")[fold][tree]\n",
    "\n",
    "uproot_v = [lee,mc,nc,nue,ext,data,dirt]\n",
    "\n",
    "variables = [\n",
    "    \"shr_dedx_Y\", \"shr_bkt_pdg\", \"p\", \"pt\", \"selected\", \"nu_pdg\", \"shr_theta\",\n",
    "    \"slpdg\", \"trk_score_v\", \"backtracked_pdg\", \"shr_theta_v\", \"trk_score_v\", # modified from shr_score_v\n",
    "    \"shr_pfp_id_v\", \"category\", \"shr_tkfit_dedx_Y\", \n",
    "    \"shr_energy_tot\", \"trk_energy_tot\", \"shr_hits_tot\", \"ccnc\", \"trk_chipr\",\n",
    "    \"trk_bkt_pdg\", \"hits_ratio\", \"n_tracks_contained\", \"shr_dedx_y_v\",\n",
    "    \"crtveto\",\"crthitpe\",\"_closestNuCosmicDist\",\"slclustfrac\",\n",
    "    \"reco_nu_vtx_x\",\"reco_nu_vtx_y\",\"reco_nu_vtx_z\",\n",
    "    \"NeutrinoEnergy2\",\n",
    "    \"run\",\"sub\",\"evt\",\n",
    "    \"nproton\", \"nu_e\", \"n_showers_contained\", \"shr_distance\", \"trk_distance\",\n",
    "    \"hits_y\", \"shr_pz\", \"shr_energy\", \"shr_dedx_U\", \"shr_dedx_V\", \"shr_phi\", \"trk_phi\", \"trk_theta\",\n",
    "    \"shr_tkfit_dedx_U\", \"shr_tkfit_dedx_V\", \"run\", \"sub\", \"evt\", \"nproton\", \"trk_pid_chipr_v\",\n",
    "    \"trk_len\", \"mc_pdg\", \"slnunhits\", \"slnhits\", \"shr_score\", \"trk_score\", \"trk_hits_tot\",\n",
    "    \"true_e_visible\", \"matched_E\", \"shr_bkt_E\", \"trk_bkt_E\", \"trk_energy\", \"tksh_distance\", \"tksh_angle\",\n",
    "    \"trk_chipr_best\", \"trk_chipr_worst\", \"trk_pida\", \"trk_chimu\", \"CosmicIP\", \"trk_bragg_p\", \"trk_bragg_mu\",\n",
    "    \"trk_bragg_mip\", \"shr_chipr\", \"shr_bragg_p\", \"shr_bragg_mu\", \"shr_chimu\",\n",
    "    \"shr_pca_2\", \"shr_pca_0\", \"shr_pca_1\", \"npi0\", \"gamma1_edep\", \"gamma2_edep\", \"topological_score\",\n",
    "    \"bdt_nuNCpi0\",\"bdt_numuCCpi0\",\"bdt_numuCC\",\"bdt_ext\",\"bdt_cosmic\",\"bdt_global\",\n",
    "    \"pi0_e\", \"shr_energy_tot_cali\", \"shr_dedx_Y_cali\", \"evnunhits\", \"nslice\", \"interaction\"#\n",
    "]\n",
    "\n",
    "nue = nue.pandas.df(variables + [\"weightSpline\", \"weightsGenie\", \"weightsFlux\", \"weightsReint\"], flatten=False)\n",
    "mc = mc.pandas.df(variables + [\"weightSpline\", \"weightsGenie\", \"weightsFlux\", \"weightsReint\"], flatten=False)\n",
    "#nc = nc.pandas.df(variables + [\"weightSpline\", \"weightsGenie\", \"weightsFlux\", \"weightsReint\"], flatten=False)\n",
    "data = data.pandas.df(variables, flatten=False)\n",
    "ext = ext.pandas.df(variables, flatten=False)\n",
    "dirt = dirt.pandas.df(variables + [\"weightSpline\", \"weightsGenie\", \"weightsFlux\", \"weightsReint\"], flatten=False)\n",
    "lee = lee.pandas.df(variables + [\"weightSpline\", \"leeweight\"], flatten=False)\n",
    "\n",
    "ext[\"shr_dedx_Y\"] = ext[\"shr_dedx_Y\"] * SHRCALIBFACTOR\n",
    "data[\"shr_dedx_Y\"] = data[\"shr_dedx_Y\"] * SHRCALIBFACTOR\n",
    "ext[\"shr_dedx_Y_cali\"] = ext[\"shr_dedx_Y_cali\"] * SHRCALIBFACTOR\n",
    "data[\"shr_dedx_Y_cali\"] = data[\"shr_dedx_Y_cali\"] * SHRCALIBFACTOR\n",
    "ext[\"shr_tkfit_dedx_Y\"] = ext[\"shr_tkfit_dedx_Y\"] * SHRCALIBFACTOR\n",
    "data[\"shr_tkfit_dedx_Y\"] = data[\"shr_tkfit_dedx_Y\"] * SHRCALIBFACTOR\n",
    "ext[\"shr_dedx_y_v\"] = ext[\"shr_dedx_y_v\"] * SHRCALIBFACTOR\n",
    "data[\"shr_dedx_y_v\"] = data[\"shr_dedx_y_v\"] * SHRCALIBFACTOR\n",
    "ext[\"shr_energy_tot\"] = ext[\"shr_energy_tot\"] * SHRCALIBFACTOR\n",
    "data[\"shr_energy_tot\"] = data[\"shr_energy_tot\"] * SHRCALIBFACTOR\n",
    "ext[\"shr_energy_tot_cali\"] = ext[\"shr_energy_tot_cali\"] * SHRCALIBFACTOR\n",
    "data[\"shr_energy_tot_cali\"] = data[\"shr_energy_tot_cali\"] * SHRCALIBFACTOR\n",
    "\n",
    "lee[\"is_signal\"] = lee[\"category\"] == 11\n",
    "data[\"is_signal\"] = data[\"category\"] == 11\n",
    "nue[\"is_signal\"] = nue[\"category\"] == 11\n",
    "mc[\"is_signal\"] = mc[\"category\"] == 11\n",
    "dirt[\"is_signal\"] = dirt[\"category\"] == 11\n",
    "ext[\"is_signal\"] = ext[\"category\"] == 11\n",
    "#nc[\"is_signal\"] = nc[\"category\"] == 11\n",
    "\n",
    "lee.loc[lee['category'] == 1, 'category'] = 111\n",
    "lee.loc[lee['category'] == 10, 'category'] = 111\n",
    "lee.loc[lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "#train_nc, nc = train_test_split(nc, test_size=0.5, random_state=1990)\n",
    "train_mc, mc = train_test_split(mc, test_size=0.5, random_state=1990)\n",
    "train_nue, nue = train_test_split(nue, test_size=0.5, random_state=1990)\n",
    "train_lee, lee = train_test_split(lee, test_size=0.5, random_state=1990)\n",
    "train_ext, ext = train_test_split(ext, test_size=0.5, random_state=1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get the LLR-PID value for the \"track candidate\" (proton for nue selection, muon for numu)\n",
    "# can be done for any variable\n",
    "# code from Giuseppe!\n",
    "\n",
    "#df_v = [lee,mc,nc,nue,ext,data,dirt]\n",
    "df_v = [lee,mc,nue,ext,data,dirt]\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    \n",
    "    trk_llr_pid_v = up.array('trk_pid_chipr_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([j[0][j[1]] if j[1]<len(j[0]) else 9999. for j in zip(trk_llr_pid_v,trk_id)])\n",
    "    \n",
    "    df['trkpid'] = trk_llr_pid_v_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcI43ileYJ9P"
   },
   "outputs": [],
   "source": [
    "features = nue_booster.variables.copy()\n",
    "features.remove(\"is_signal\")\n",
    "features.remove(\"nu_e\")\n",
    "features.remove(\"train_weight\")\n",
    "# features.remove('shr_energy_tot_cali')\n",
    "# features.remove('trk_energy_tot')\n",
    "\n",
    "for label, bkg_query in zip(nue_booster.labels, nue_booster.bkg_queries):\n",
    "    with open(ls.pickle_path+'booster_%s.pickle' % label, 'rb') as booster_file:\n",
    "        booster = pickle.load(booster_file)\n",
    "        mc[label+\"_score\"] = booster.predict(\n",
    "            xgb.DMatrix(mc[features]),\n",
    "            ntree_limit=booster.best_iteration + 1)\n",
    "        nue[label+\"_score\"] = booster.predict(\n",
    "            xgb.DMatrix(nue[features]),\n",
    "            ntree_limit=booster.best_iteration + 1)\n",
    "        ext[label+\"_score\"] = booster.predict(\n",
    "            xgb.DMatrix(ext[features]),\n",
    "            ntree_limit=booster.best_iteration + 1)\n",
    "        data[label+\"_score\"] = booster.predict(\n",
    "            xgb.DMatrix(data[features]),\n",
    "            ntree_limit=booster.best_iteration + 1)\n",
    "        dirt[label+\"_score\"] = booster.predict(\n",
    "            xgb.DMatrix(dirt[features]),\n",
    "            ntree_limit=booster.best_iteration + 1)\n",
    "        lee[label+\"_score\"] = booster.predict(\n",
    "            xgb.DMatrix(lee[features]),\n",
    "            ntree_limit=booster.best_iteration + 1)\n",
    "        #nc[label+\"_score\"] = booster.predict(\n",
    "        #    xgb.DMatrix(nc[features]),\n",
    "        #    ntree_limit=booster.best_iteration + 1)\n",
    "features = [\"%s_score\" % l for l in nue_booster.labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ls.pickle_path+'booster.pickle', 'rb') as booster_file:\n",
    "    booster = pickle.load(booster_file)\n",
    "    \n",
    "    mc[\"global_score\"] = booster.predict(\n",
    "        xgb.DMatrix(mc[features]),\n",
    "        ntree_limit=booster.best_iteration + 1)\n",
    "    nue[\"global_score\"] = booster.predict(\n",
    "        xgb.DMatrix(nue[features]),\n",
    "        ntree_limit=booster.best_iteration + 1)\n",
    "    ext[\"global_score\"] = booster.predict(\n",
    "        xgb.DMatrix(ext[features]),\n",
    "        ntree_limit=booster.best_iteration + 1)\n",
    "    data[\"global_score\"] = booster.predict(\n",
    "        xgb.DMatrix(data[features]),\n",
    "        ntree_limit=booster.best_iteration + 1)\n",
    "    dirt[\"global_score\"] = booster.predict(\n",
    "        xgb.DMatrix(dirt[features]),\n",
    "        ntree_limit=booster.best_iteration + 1)\n",
    "    lee[\"global_score\"] = booster.predict(\n",
    "        xgb.DMatrix(lee[features]),\n",
    "        ntree_limit=booster.best_iteration + 1)\n",
    "    #nc[\"global_score\"] = booster.predict(\n",
    "    #    xgb.DMatrix(nc[features]),\n",
    "    #    ntree_limit=booster.best_iteration + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pamv0W8YJ9R"
   },
   "outputs": [],
   "source": [
    "lee[\"reco_e\"] = (lee[\"shr_energy_tot_cali\"] + 0.030) / 0.79 + lee[\"trk_energy_tot\"]\n",
    "data[\"reco_e\"] = (data[\"shr_energy_tot_cali\"] + 0.030) / 0.79 + data[\"trk_energy_tot\"]\n",
    "nue[\"reco_e\"] = (nue[\"shr_energy_tot_cali\"] + 0.030) / 0.79 + nue[\"trk_energy_tot\"]\n",
    "mc[\"reco_e\"] = (mc[\"shr_energy_tot_cali\"] + 0.030) / 0.79 + mc[\"trk_energy_tot\"]\n",
    "dirt[\"reco_e\"] = (dirt[\"shr_energy_tot_cali\"] + 0.030) / 0.79 + dirt[\"trk_energy_tot\"]\n",
    "ext[\"reco_e\"] = (ext[\"shr_energy_tot_cali\"] + 0.030) / 0.79 + ext[\"trk_energy_tot\"]\n",
    "#nc[\"reco_e\"] = (nc[\"shr_energy_tot_cali\"] + 0.030) / 0.79 + nc[\"trk_energy_tot\"]\n",
    "\n",
    "samples = {\n",
    "    \"mc\": mc,\n",
    "    \"nue\": nue,\n",
    "    \"data\": data,\n",
    "    \"ext\": ext,\n",
    "    \"dirt\": dirt,\n",
    "    #\"nc\": nc,\n",
    "    \"lee\": lee\n",
    "}\n",
    "\n",
    "scaling = 1#132.0/4.5\n",
    "\n",
    "SPLIT = 2.\n",
    "\n",
    "#''' 1013\n",
    "weights = {\n",
    "    \"mc\": 0.0107 * SPLIT * scaling,\n",
    "    \"nue\": 0.00008 * SPLIT * scaling,\n",
    "    \"ext\": 0.0718 * SPLIT * scaling,\n",
    "    \"dirt\": 0.0342 * scaling,\n",
    "    \"lee\": 0.00008 * SPLIT * scaling,\n",
    "    #\"nc\": 0.021023 * 2 * scaling,\n",
    "}\n",
    "#'''\n",
    "\n",
    "\n",
    "\n",
    "my_plotter = plotter.Plotter(samples, weights, pot=0.9e19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# giuseppe's box cuts\n",
    "QUERY = \"selected == 1\"\n",
    "QUERY += \" and (crtveto!=1 or crthitpe < 100.) and (_closestNuCosmicDist > 20.)\"\n",
    "QUERY += \" and (reco_nu_vtx_x>20 & reco_nu_vtx_x<230) \"\n",
    "QUERY += \" and (reco_nu_vtx_y>-95 & reco_nu_vtx_y<95)\"\n",
    "QUERY += \" and n_showers_contained==1\"\n",
    "QUERY += \" and shr_energy_tot_cali>0.08\"\n",
    "QUERY += \" and hits_y>50\"\n",
    "QUERY += \" and hits_ratio>0.65\"\n",
    "QUERY += \" and CosmicIP>30\"\n",
    "QUERY += \" and shr_distance<2.5\"\n",
    "QUERY += \" and trk_distance<2.5\"\n",
    "QUERY += \" and tksh_distance<2\"\n",
    "QUERY += \" and tksh_angle>-0.9\"\n",
    "QUERY += \" and (shr_tkfit_dedx_Y>0.5 & shr_tkfit_dedx_Y<3.5)\"\n",
    "QUERY += \" and shr_score<0.125\"\n",
    "QUERY += \" and trk_score>0.85\"\n",
    "QUERY += \" and slclustfrac>0.6\"\n",
    "#QUERY += \" and reco_e_rqe>0.8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nue pre-selection w/ CRT\n",
    "QUERY = 'selected == 1'\n",
    "QUERY += ' and (crtveto!=1 or crthitpe < 100.) and (_closestNuCosmicDist > 20.)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BDT additon\n",
    "QUERY += ' and global_score > 0.9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2342,
     "status": "ok",
     "timestamp": 1560557343774,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "b93hN-pGYJ9T",
    "outputId": "17e7c7ed-3f12-4b03-805c-6698f1617878",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "miniboone_bins = [\n",
    "    0, 0.200, 0.300, 0.375, 0.475, 0.550, 0.675, 0.800, 0.950, 1.100, 1.300,\n",
    "    1.500, 3.000\n",
    "]\n",
    "\n",
    "fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "    \"reco_e\",\n",
    "    query=QUERY,\n",
    "    kind=\"event_category\",\n",
    "    #kind=\"interaction\",\n",
    "    #kind=\"sample\",\n",
    "    draw_sys=False,\n",
    "    title=r\"$E_{deposited}$ [GeV]\",\n",
    "    #bins=miniboone_bins,\n",
    "    bins=10,\n",
    "    range=(0.,1.0),\n",
    ")\n",
    "\n",
    "print(\"Profile likelihood: %.2f sigma @ 1.32e21 POT\" % my_plotter.significance_likelihood)\n",
    "print(\"s/sqrt(b): %.2f sigma @ 1.32e21 POT\" % my_plotter.significance)\n",
    "\n",
    "# ax1.set_ylim(0,450)\n",
    "# ax1.set_yscale(\"log\")\n",
    "# ax1.set_ylim(0,1)\n",
    "ax2.set_ylim(0.5,1.5)\n",
    "fig.savefig(ls.plots_path+\"spectrum.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_range = (0.1,0.8)\n",
    "n_bins = 7\n",
    "\n",
    "n_tot = np.empty([50, n_bins])\n",
    "n_cv_tot = np.empty(n_bins)\n",
    "n_tot.fill(0)\n",
    "n_cv_tot.fill(0)\n",
    "score_cut = 0.997\n",
    "\n",
    "my_cmap = cm.get_cmap('viridis')\n",
    "\n",
    "for t in samples:\n",
    "    if t in [\"ext\", \"data\", \"lee\"]:\n",
    "        continue\n",
    "    tree = samples[t]\n",
    "    \n",
    "    extra_query = \"\"\n",
    "    if t == \"mc\":\n",
    "        extra_query = \"& ~(nu_pdg == 12 & ccnc == 0) & ~(npi0 != 0 & ccnc == 1)\"\n",
    "        \n",
    "    queried_tree = tree.query(\"selected==1 & global_score > %g %s & interaction == 1\" % (score_cut, extra_query))\n",
    "    variable = queried_tree[\"reco_e\"]\n",
    "    genie_weights = queried_tree[\"weightsGenie\"]\n",
    "    spline_fix = queried_tree[\"weightSpline\"]*weights[t]\n",
    "\n",
    "    s = genie_weights\n",
    "    df = pd.DataFrame(s.values.tolist())\n",
    "\n",
    "\n",
    "    n_cv, bins = np.histogram(\n",
    "        variable,\n",
    "        range=x_range,\n",
    "        bins=n_bins,\n",
    "        weights=spline_fix)\n",
    "    \n",
    "    n_cv_tot += n_cv\n",
    "\n",
    "    if not df.empty:\n",
    "        for i in range(50):\n",
    "            weight = df[i].values\n",
    "            weight[np.isnan(weight)] = 1\n",
    "            weight[weight > 100] = 1\n",
    "\n",
    "            n, bins = np.histogram(\n",
    "                variable, weights=weight*spline_fix, range=x_range, bins=n_bins)\n",
    "\n",
    "            n_tot[i] += n\n",
    "\n",
    "        \n",
    "bincenters = 0.5 * (bins[1:] + bins[:-1])\n",
    "\n",
    "left,right = bins[:-1],bins[1:]\n",
    "X = np.array([left,right]).T.flatten()\n",
    "Y = np.array([n_cv_tot,n_cv_tot]).T.flatten()\n",
    "plt.plot(X,Y,color='r',linewidth=2,label='Central value')\n",
    "\n",
    "    \n",
    "cov = np.empty([len(n_cv), len(n_cv)])\n",
    "cov.fill(0)\n",
    "\n",
    "my_norm = Normalize(vmin=min((sum(n) for n in n_tot)), vmax=max((sum(n) for n in n_tot)))\n",
    "\n",
    "for n in n_tot:\n",
    "    left,right = bins[:-1],bins[1:]\n",
    "    X = np.array([left,right]).T.flatten()\n",
    "    Y = np.array([n,n]).T.flatten()\n",
    "    plt.plot(X,Y,color=my_cmap(my_norm(sum(n))),zorder=-32)\n",
    "    for i in range(len(n_cv)):\n",
    "        for j in range(len(n_cv)):\n",
    "            cov[i][j] += (n[i] - n_cv_tot[i]) * (n[j] - n_cv_tot[j])\n",
    "\n",
    "cov /= 50\n",
    "            \n",
    "frac_cov = np.empty([len(n_cv), len(n_cv)])\n",
    "corr = np.empty([len(n_cv), len(n_cv)])\n",
    "\n",
    "for i in range(len(n_cv)):\n",
    "    for j in range(len(n_cv)):\n",
    "        frac_cov[i][j] = cov[i][j] / (n_cv_tot[i] * n_cv_tot[j])\n",
    "        corr[i][j] = cov[i][j] / np.sqrt(cov[i][i] * cov[j][j])\n",
    "\n",
    "        \n",
    "plt.errorbar(\n",
    "    bincenters, \n",
    "    n_cv_tot,\n",
    "    yerr=np.sqrt(np.diag(cov)), \n",
    "    fmt='none', \n",
    "    ecolor='r',\n",
    "    linewidth=2,\n",
    "    label='GENIE sys. uncertainties')\n",
    "\n",
    "print(np.sqrt(np.diag(cov))/n_cv_tot)\n",
    "plt.xlim(x_range[0], x_range[1])\n",
    "plt.xlabel(r\"$E_{deposited}$ [GeV]\")\n",
    "plt.legend()\n",
    "plt.ylim(ymin=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/spec.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "pos = ax.imshow(frac_cov, origin='lower', cmap='viridis')\n",
    "ax.set_title(\"Fractional covariance matrix\")\n",
    "ax.set_ylabel(\"Bin number\")\n",
    "ax.set_xlabel(\"Bin number\")\n",
    "fig.colorbar(pos)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"plots/frac.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_title(\"Correlation matrix\")\n",
    "pos = ax.imshow(corr, origin='lower', cmap='inferno')\n",
    "ax.set_ylabel(\"Bin number\")\n",
    "ax.set_xlabel(\"Bin number\")\n",
    "fig.colorbar(pos)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"plots/corr.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_plotter.plot_2d(\n",
    "    \"global_score\",\n",
    "    \"ncpi0_score\",\n",
    "    query=\"selected==1\",\n",
    "    bins_x=50,\n",
    "    bins_y=50,\n",
    "    range_x=(0., 1),\n",
    "    range_y=(0., 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Plotter.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
