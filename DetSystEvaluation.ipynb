{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import localSettings as ls\n",
    "print(ls.main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1560556807118,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "6qsD0G-yYJ9K",
    "outputId": "5d52a3ec-50be-44fc-da44-3c0593e98bc6"
   },
   "outputs": [],
   "source": [
    "main_path = ls.main_path\n",
    "sys.path.append(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%m%d%Y\")\n",
    "print(\"date and time:\",date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHRCALIBFACTOR = 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Run3?\n",
    "ISRUN3 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGqTJ5JgaDsx"
   },
   "outputs": [],
   "source": [
    "import plotter\n",
    "import importlib\n",
    "importlib.reload(plotter)\n",
    "import uproot\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import xgboost as xgb #don't necessarily need for NUMU\n",
    "import nue_booster \n",
    "importlib.reload(nue_booster)\n",
    "import awkward\n",
    "import pandas as pd\n",
    "\n",
    "params = {\n",
    "    'axes.labelsize': 'x-large',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'ytick.labelsize': 'x-large'\n",
    "}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    \"shr_dedx_Y\", \"shr_bkt_pdg\", \"p\", \"pt\", \"selected\", \"nu_pdg\", \"shr_theta\",\n",
    "    \"slpdg\", \"trk_score_v\", \"backtracked_pdg\", # modified from shr_score_v\n",
    "    \"shr_pfp_id_v\", \"category\", \"shr_tkfit_dedx_Y\",\n",
    "    \"shr_tkfit_gap10_dedx_U\",\"shr_tkfit_gap10_dedx_V\",\"shr_tkfit_gap10_dedx_Y\",\n",
    "    \"shr_tkfit_2cm_dedx_U\",\"shr_tkfit_2cm_dedx_V\",\"shr_tkfit_2cm_dedx_Y\",\n",
    "    #\"shr_energy_tot\", \n",
    "    \"trk_energy_tot\", \"shr_hits_tot\", \"ccnc\", \"trk_chipr\",\n",
    "    \"trk_bkt_pdg\", \"hits_ratio\", \"n_tracks_contained\", \n",
    "    #\"crtveto\",\"crthitpe\",\"_closestNuCosmicDist\",\n",
    "    \"NeutrinoEnergy2\",\n",
    "    #\"run\",\"sub\",\"evt\",\n",
    "    \"CosmicIP\",\n",
    "    \"flash_pe\",\n",
    "    \"nu_flashmatch_score\",\"best_cosmic_flashmatch_score\",\"best_obviouscosmic_flashmatch_score\",\n",
    "    #\"trk_pfp_id\",\n",
    "    \"shrmoliereavg\",\"shrmoliererms\",\n",
    "    \"shr_tkfit_npointsvalid\",\"shr_tkfit_npoints\", # fitted vs. all hits for shower\n",
    "    \"shrclusfrac0\",\"shrclusfrac1\",\"shrclusfrac2\", # track-fitted hits / all hits\n",
    "    \"trkshrhitdist2\", # \"trkshrhitdist0\",\"trkshrhitdist1\", distance between track and shower in 2D\n",
    "    \"shrsubclusters0\",\"shrsubclusters1\",\"shrsubclusters2\", # number of sub-clusters in shower\n",
    "    \"trk_llr_pid_score_v\", # trk-PID score\n",
    "    \"trk_energy_proton_v\", # track energy under proton hyp\n",
    "    \"trk_calo_energy_y_v\", # track calo energy\n",
    "    #\"pi0_energy2_Y\", # pi0 tagger variables\n",
    "    \"filter_pi0\",\n",
    "    \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "    \"nproton\", \"nu_e\", \"n_showers_contained\", \"shr_distance\", \"trk_distance\",\n",
    "    \"hits_y\", \"shr_pz\", \"shr_energy\", \"shr_dedx_U\", \"shr_dedx_V\", \"shr_phi\", \"trk_phi\", \"trk_theta\",\n",
    "    \"shr_tkfit_dedx_U\", \"shr_tkfit_dedx_V\", \"run\", \"sub\", \"evt\", \"nproton\", \"trk_pid_chipr_v\",\n",
    "    \"trk_len\", \"mc_pdg\", \"slnunhits\", \"slnhits\", \"shr_score\", \"trk_score\", \"trk_hits_tot\",\n",
    "    \"true_e_visible\", \"matched_E\", \"shr_bkt_E\", \"trk_bkt_E\", \"trk_energy\", \"tksh_distance\", \"tksh_angle\",\n",
    "    \"npi0\",\"npion\",\"pion_e\",\"muon_e\",\"pi0truth_elec_etot\",\n",
    "    \"pi0_e\", \"shr_energy_tot_cali\", \"shr_dedx_Y_cali\", \"evnunhits\", \"nslice\", \"interaction\",\n",
    "    \"slclustfrac\", \"reco_nu_vtx_x\", \"reco_nu_vtx_y\", \"reco_nu_vtx_z\",\"contained_fraction\",\n",
    "    \"secondshower_Y_nhit\",\"secondshower_Y_vtxdist\",\"secondshower_Y_dot\",\"secondshower_Y_dir\",\"shrclusdir2\",\n",
    "    \"shr_tkfit_2cm_nhits_Y\",\"shr_tkfit_2cm_nhits_U\",\"shr_tkfit_2cm_nhits_V\",\n",
    "    \"shr_tkfit_gap10_nhits_Y\",\"shr_tkfit_gap10_nhits_U\",\"shr_tkfit_gap10_nhits_V\",\n",
    "    \"weightSpline\",\"weightTune\",\"weightSplineTimesTune\",\n",
    "    # pi0 selection variables\n",
    "    \"pi0_radlen1\",\"pi0_radlen2\",\"pi0_dot1\",\"pi0_dot2\",\"pi0_energy1_Y\",\"pi0_energy2_Y\",\n",
    "    \"pi0_dedx1_fit_Y\",\"pi0_dedx2_fit_Y\",\"pi0_shrscore1\",\"pi0_shrscore2\",\"pi0_gammadot\",\n",
    "    \"pi0_dedx1_fit_V\",\"pi0_dedx2_fit_V\",\"pi0_dedx1_fit_U\",\"pi0_dedx2_fit_U\",\n",
    "    \"pi0_mass_Y\",\"pi0_mass_V\",\"pi0_mass_U\",\n",
    "    'topological_score','trk_theta_v',\n",
    "    'trk_sce_start_x_v','trk_sce_start_y_v','trk_sce_start_z_v',\n",
    "    'trk_sce_end_x_v','trk_sce_end_y_v','trk_sce_end_z_v',\n",
    "    'trk_len_v','pfp_generation_v','trk_distance_v',\n",
    "    'trk_mcs_muon_mom_v','trk_range_muon_mom_v',\n",
    "    'trk_energy_muon','trk_energy_tot','trk_energy'\n",
    "]\n",
    "\n",
    "#remove possible redundancies\n",
    "variables = list(set(variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beginning of selection-specific cuts\n",
    "#### Nue\n",
    "#### Loose box cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nue preselection\n",
    "PRESQ = 'nslice == 1'\n",
    "PRESQ += ' and selected == 1'\n",
    "PRESQ += ' and n_tracks_contained > 0'\n",
    "PRESQ += ' and shr_energy_tot_cali > 0.07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loose box cuts\n",
    "LCUTQ = PRESQ\n",
    "LCUTQ += ' and n_showers_contained == 1'\n",
    "LCUTQ += ' and hits_ratio > 0.5'\n",
    "LCUTQ += ' and tksh_distance < 6.0'\n",
    "LCUTQ += ' and shr_tkfit_2cm_dedx_avg < 4.0'\n",
    "LCUTQ += ' and tksh_angle > -0.9'\n",
    "LCUTQ += ' and trkpid < 0.1'\n",
    "LCUTQ += ' and shr_score < 0.40'\n",
    "LCUTQ += ' and CosmicIP > 20.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tight box cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tight box cuts\n",
    "TCUTQ = LCUTQ\n",
    "TCUTQ += ' and tksh_distance < 4.0'\n",
    "#TCUTQ += ' and (shr_tkfit_2cm_nhits_Y > 0)'\n",
    "#TCUTQ += ' and (shr_tkfit_2cm_dedx_Y < 4.0 and shr_tkfit_2cm_dedx_U < 4.0 and shr_tkfit_2cm_dedx_V < 4.0)'\n",
    "#TCUTQ += ' and (shr_tkfit_gap10_dedx_Y < 4.5)'\n",
    "#\n",
    "TCUTQ += ' and (shr_tkfit_2cm_nhits_tot > 1)'\n",
    "TCUTQ += ' and (shr_tkfit_2cm_dedx_avg < 3.8)'\n",
    "TCUTQ += ' and (shr_tkfit_gap10_nhits_tot > 1)'\n",
    "TCUTQ += ' and (shr_tkfit_gap10_dedx_avg < 3.8)'\n",
    "#\n",
    "TCUTQ += ' and tksh_angle > -0.9 and tksh_angle < 0.75'\n",
    "TCUTQ += ' and shrmoliereavg > 2 and shrmoliereavg < 10'\n",
    "TCUTQ += ' and trkpid < 0.02'\n",
    "TCUTQ += ' and n_showers_contained == 1'\n",
    "TCUTQ += ' and shr_score < 0.275'\n",
    "TCUTQ += ' and hits_ratio > 0.60'\n",
    "TCUTQ += ' and (secondshower_Y_nhit<=8 or secondshower_Y_dot<=0.8 or anglediff_Y<=40 or secondshower_Y_vtxdist>=100)'\n",
    "TCUTQ += ' and subcluster > 7'\n",
    "TCUTQ += ' and trkfit < 0.70'\n",
    "TCUTQ += ' and trkshrhitdist2 < 1.5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pi0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pi0 selection\n",
    "LOOSE = True\n",
    "if (LOOSE):\n",
    "    SCORECUT = 0.8 # 0.75 #75 # max track score\n",
    "    DVTX = 3.0 # 3. # distance from vertex of each shower\n",
    "    VTXDOT = 0.8 # dot product between each shower's direction and the vtx -> shr start vector\n",
    "    EMIN1 =  50. # leading photon min energy\n",
    "    EMIN2 =  20. #20. # 20. # subleading photon min energy\n",
    "    GAMMADOT = 0.94 # max dot product between showres\n",
    "    DEDXCUT = 0.0 # MeV/cm cut on leading shower only\n",
    "else:\n",
    "    SCORECUT = 0.5 # 0.75 #75 # max track score\n",
    "    DVTX = 3.0 # 3. # distance from vertex of each shower\n",
    "    VTXDOT = 0.8 # dot product between each shower's direction and the vtx -> shr start vector\n",
    "    EMIN1 =  60. # leading photon min energy\n",
    "    EMIN2 =  40. #20. # 20. # subleading photon min energy\n",
    "    GAMMADOT = 0.94 # max dot product between showres\n",
    "    DEDXCUT = 1.0 # MeV/cm cut on leading shower only\n",
    "\n",
    "PI0SEL = 'nslice == 1'\n",
    "PI0SEL += ' & pi0_shrscore1 < %f & pi0_shrscore2 < %f'%(SCORECUT,SCORECUT)\n",
    "PI0SEL += '& pi0_dot1  > %f & pi0_dot2 > %f '%(VTXDOT,VTXDOT)\n",
    "PI0SEL += ' & pi0_radlen1 > %f & pi0_radlen2 > %f & pi0_gammadot < %f '%(DVTX,DVTX,GAMMADOT)\n",
    "PI0SEL += ' & pi0_energy1_Y > %f & pi0_energy2_Y > %f'%(EMIN1,EMIN2)\n",
    "#PI0SEL += ' and (filter_pi0 == 1 or bnbdata==1 or extdata==1)'\n",
    "PI0SEL += ' and pi0_dedx1_fit_Y >= %f'%DEDXCUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NUMU Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Cuts for NUMU constraint selection\n",
    "####################################\n",
    "\n",
    "#updated for SCE\n",
    "#will swap numerical vals at end\n",
    "FVx = [10,246]#[5,251]\n",
    "FVy = [-110,110]\n",
    "FVz = [20,986]\n",
    "\n",
    "QUERY = '' #cuts on event-level variables\n",
    "for a,APPEND in enumerate(['CV','VAR']):\n",
    "    if a > 0:\n",
    "        QUERY += ' and '\n",
    "    QUERY += 'nslice_{} == 1'.format(APPEND)\n",
    "    QUERY += ' and topological_score_{} > 0.06'.format(APPEND)\n",
    "    QUERY += ' and reco_nu_vtx_sce_x_{} > FVx[0] and reco_nu_vtx_sce_x_{} < FVx[1]'.format(APPEND,APPEND)\n",
    "    QUERY += ' and reco_nu_vtx_sce_y_{} > FVy[0] and reco_nu_vtx_sce_y_{} < FVy[1]'.format(APPEND,APPEND)\n",
    "    QUERY += ' and reco_nu_vtx_sce_z_{} > FVz[0] and reco_nu_vtx_sce_z_{} < FVz[1]'.format(APPEND,APPEND)\n",
    "    QUERY += ' and ( (reco_nu_vtx_sce_z_{} < 675) or (reco_nu_vtx_sce_z_{} > 775) )'.format(APPEND,APPEND) #avoid dead wire region    \n",
    "    #if ISRUN3: QUERY += ' and (crtveto_{}!=1 or crthitpe_{} < 100.) and (_closestNuCosmicDist_{} > 20.)'.format(APPEND,APPEND,APPEND)\n",
    "    \n",
    "QUERY = QUERY.replace('FVx[0]',str(FVx[0]))\n",
    "QUERY = QUERY.replace('FVy[0]',str(FVy[0]))\n",
    "QUERY = QUERY.replace('FVz[0]',str(FVz[0]))\n",
    "QUERY = QUERY.replace('FVx[1]',str(FVx[1]))\n",
    "QUERY = QUERY.replace('FVy[1]',str(FVy[1]))\n",
    "QUERY = QUERY.replace('FVz[1]',str(FVz[1])) \n",
    "\n",
    "print (\"QUERY: \\n\",QUERY)\n",
    "\n",
    "track_cuts = [\n",
    "    ('trk_sce_start_x_v', '>', FVx[0]),\n",
    "    ('trk_sce_start_x_v', '<', FVx[1]),\n",
    "    ('trk_sce_start_y_v', '>', FVy[0]),\n",
    "    ('trk_sce_start_y_v', '<', FVy[1]),\n",
    "    ('trk_sce_start_z_v', '>', FVz[0]),\n",
    "    ('trk_sce_start_z_v', '<', FVz[1]),\n",
    "    ('trk_sce_end_x_v', '>', FVx[0]),\n",
    "    ('trk_sce_end_x_v', '<', FVx[1]),\n",
    "    ('trk_sce_end_y_v', '>', FVy[0]),\n",
    "    ('trk_sce_end_y_v', '<', FVy[1]),\n",
    "    ('trk_sce_end_z_v', '>', FVz[0]),\n",
    "    ('trk_sce_end_z_v', '<', FVz[1]),\n",
    "    ('trk_p_quality_v', '>', -0.5),\n",
    "    ('trk_p_quality_v', '<', 0.5),\n",
    "    ('trk_llr_pid_score_v', '>', 0.2),\n",
    "    ('trk_score_v', '>', 0.8),\n",
    "    ('trk_len_v', '>', 10),\n",
    "    ('pfp_generation_v', '==', 2),\n",
    "    ('trk_distance_v', '<', 4)\n",
    "]\n",
    "\n",
    "print(\"\\ntrack cuts:\")\n",
    "\n",
    "cut_string = \"\"\n",
    "for c,cut in enumerate(track_cuts):\n",
    "    if c > 0: cut_string += \" and \"\n",
    "    if type(cut[1]) == list: cut_string += \"( ({} {} {}) or ({} {} {}) )\".format(cut[0],cut[1][0],cut[2][0],cut[0],cut[1][1],cut[2][1])\n",
    "    else: cut_string += \"{} {} {}\".format(cut[0],cut[1],cut[2])\n",
    "print(cut_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes and make a bunch of calculated columns.\n",
    "### Final dataframe will have odd structure\n",
    "#### cuts will need to look like \"varname_VAR\" or \"varname_CV\" to cut on variation or central-value example of the cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ls)\n",
    "fold = \"nuselection\"\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "\n",
    "'''\n",
    "#NUECV = \"prodgenie_bnb_nu_uboone_overlay_mcc9.1_det_var_v08_00_00_26_CV_run1_reco2_reco2.root\"\n",
    "NUECV = \"/home/david/data/searchingfornues/v08_00_00_33/cc0pinp/0218/run1/prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2.root\"\n",
    "NUELY = \"prodgenie_bnb_intrinsic_nue_uboone_overlay_mcc9_reco2_LYdown_v08_00_00_32_run1_reco2_reco2.root\"\n",
    "NUEWA = \"prodgenie_bnb_intrinsic_nue_uboone_overlay_wiremodangle_mcc9.1_v08_00_00_30_run1_reco2_reco2.root\"\n",
    "NUEWX = \"prodgenie_bnb_intrinsic_nue_uboone_overlay_wiremodx_mcc9.1_v08_00_00_30_run1_reco2_reco2.root\"\n",
    "NUEWYZ = \"prodgenie_bnb_intrinsic_nue_uboone_overlay_wiremodyz_mcc9.1_v08_00_00_31_run1_reco2_reco2.root\"\n",
    "    \n",
    "DETVAR_N_V = ['LY','WireMod angle','WireMod X','WireMod YZ']\n",
    "\n",
    "DETVAR_S_V = [NUELY,NUEWA,NUEWX,NUEWYZ]\n",
    "'''\n",
    "\n",
    "#'''\n",
    "NUMUCV = \"prodgenie_bnb_nu_overlay_DetVar_CV_reco2_v08_00_00_38_run3b_reco2_reco2.root\"\n",
    "#NUMUCV = \"/home/david/data/searchingfornues/v08_00_00_33/cc0pinp/0218/run1/prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run1_reco2_reco2.root\"\n",
    "NUMULYATT = \"prodgenie_bnb_nu_overlay_DetVar_LYAttenuation_v08_00_00_38_run3b_reco2_reco2.root\"\n",
    "NUMULYDOWN = \"prodgenie_bnb_nu_overlay_DetVar_LYDown_v08_00_00_37_v2_run3b_reco2_reco2.root\"\n",
    "NUMURY = \"prodgenie_bnb_nu_overlay_DetVar_LYRayleigh_v08_00_00_37_run3b_reco2_reco2.root\"\n",
    "NUMUSCE = \"prodgenie_bnb_nu_overlay_DetVar_SCE_reco2_v08_00_00_38_run3b_reco2_reco2.root\"\n",
    "NUMUWX = \"prodgenie_bnb_nu_overlay_DetVar_wiremod_ScaleX_v08_00_00_38_run3b_reco2_reco2.root\"\n",
    "NUMUWYZ = \"prodgenie_bnb_nu_overlay_DetVar_wiremod_ScaleYZ_v08_00_00_38_run3b_reco2_reco2.root\"\n",
    "NUMUWAXZ = \"prodgenie_bnb_nu_overlay_DetVar_WireModAngleXZ_v08_00_00_38_exe_run3b_reco2_reco2.root\"\n",
    "NUMUWAYZ = \"prodgenie_bnb_nu_overlay_DetVar_WireModAngleYZ_v08_00_00_38_exe_run3b_reco2_reco2.root\"\n",
    "NUMUWDEDX = \"prodgenie_bnb_nu_overlay_DetVar_wiremod_ScaledEdX_v08_00_00_39_run3b_reco2_reco2.root\"\n",
    "NUMURECOMB = \"prodgenie_bnb_nu_overlay_DetVar_Recomb2_reco2_v08_00_00_39_run3b_reco2_reco2.root\"\n",
    "    \n",
    "DETVAR_N_V = ['LY Attenuation','LY Down','Rayleigh','SCE',\n",
    "              'WireMod X','WireMod YZ',\n",
    "              'WireMod Angle XZ','WireMod Angle YZ',\n",
    "             'WireMod dEdX', 'Recomb']\n",
    "\n",
    "DETVAR_S_V = [NUMULYATT,NUMULYDOWN, NUMURY, NUMUSCE,\n",
    "              NUMUWX, NUMUWYZ,\n",
    "              NUMUWAXZ, NUMUWAYZ,\n",
    "             NUMUWDEDX,NUMURECOMB]\n",
    "\n",
    "#'''\n",
    "\n",
    "#CV = uproot.open(NUECV)[fold][tree]\n",
    "CV = uproot.open(ls.ntuple_path+NUMUCV)[fold][tree]\n",
    "\n",
    "CVDF  = CV.pandas.df(variables, flatten=False)\n",
    "\n",
    "CVDF['identifier'] = CVDF['run']*100000 + CVDF['evt']\n",
    "\n",
    "CVDF.loc[ CVDF['weightSplineTimesTune'] <= 0, 'weightSplineTimesTune' ] = 1.\n",
    "CVDF.loc[ CVDF['weightSplineTimesTune'] == np.inf, 'weightSplineTimesTune' ] = 1.\n",
    "CVDF.loc[ CVDF['weightSplineTimesTune'] > 100, 'weightSplineTimesTune' ] = 1.\n",
    "CVDF.loc[ np.isnan(CVDF['weightSplineTimesTune']) == True, 'weightSplineTimesTune' ] = 1.\n",
    "\n",
    "#'''\n",
    "\n",
    "M_mu = 0.105 #GeV/c\n",
    "M_p = 0.938 #GeV/c\n",
    "\n",
    "\n",
    "trk_llr_pid_v = CV.array('trk_llr_pid_score_v')\n",
    "trk_energy_proton_v = CV.array('trk_energy_proton_v')\n",
    "trk_calo_energy_y_v = CV.array('trk_calo_energy_y_v')\n",
    "trk_id = CV.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "trk_energy_proton_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_energy_proton_v,trk_id)])\n",
    "trk_calo_energy_y_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_calo_energy_y_v,trk_id)])\n",
    "CVDF['trkpid'] = trk_llr_pid_v_sel\n",
    "CVDF['protonenergy'] = trk_energy_proton_sel\n",
    "CVDF['trackcaloenergy'] = trk_calo_energy_y_sel\n",
    "CVDF['subcluster'] = CVDF['shrsubclusters0'] + CVDF['shrsubclusters1'] + CVDF['shrsubclusters2']\n",
    "CVDF['trkfit'] = CVDF['shr_tkfit_npointsvalid'] / CVDF['shr_tkfit_npoints']\n",
    "CVDF['anglediff_Y'] = np.abs(CVDF['secondshower_Y_dir']-CVDF['shrclusdir2'])\n",
    "\n",
    "CVDF['shr_tkfit_2cm_nhits_tot'] = (CVDF['shr_tkfit_2cm_nhits_Y']+CVDF['shr_tkfit_2cm_nhits_U']+CVDF['shr_tkfit_2cm_nhits_V'])\n",
    "CVDF['shr_tkfit_2cm_dedx_avg'] = (CVDF['shr_tkfit_2cm_nhits_Y']*CVDF['shr_tkfit_2cm_dedx_Y'] + CVDF['shr_tkfit_2cm_nhits_U']*CVDF['shr_tkfit_2cm_dedx_U'] + CVDF['shr_tkfit_2cm_nhits_V']*CVDF['shr_tkfit_2cm_dedx_V'])/CVDF['shr_tkfit_2cm_nhits_tot']\n",
    "CVDF['shr_tkfit_gap10_nhits_tot'] = (CVDF['shr_tkfit_gap10_nhits_Y']+CVDF['shr_tkfit_gap10_nhits_U']+CVDF['shr_tkfit_gap10_nhits_V'])\n",
    "CVDF['shr_tkfit_gap10_dedx_avg'] = (CVDF['shr_tkfit_gap10_nhits_Y']*CVDF['shr_tkfit_gap10_dedx_Y'] + CVDF['shr_tkfit_gap10_nhits_U']*CVDF['shr_tkfit_gap10_dedx_U'] + CVDF['shr_tkfit_gap10_nhits_V']*CVDF['shr_tkfit_gap10_dedx_V'])/CVDF['shr_tkfit_gap10_nhits_tot']\n",
    "\n",
    "#cuts used for muon selection\n",
    "CVDF['trk_p_quality_v'] = (CVDF['trk_mcs_muon_mom_v']-CVDF['trk_range_muon_mom_v'])/CVDF['trk_range_muon_mom_v']\n",
    "CVDF['trk_costheta_v'] = CVDF['trk_theta_v'].apply(lambda x: np.cos(x))\n",
    "CVDF['reco_nu_e_range'] = CVDF[\"trk_energy_muon\"] + (CVDF[\"trk_energy_tot\"] - CVDF[\"trk_energy\"]) + M_mu\n",
    "CVDF['reco_muon_e_range'] = CVDF[\"trk_energy_muon\"] + M_mu\n",
    "\n",
    "CVDF[\"is_signal\"] = CVDF[\"category\"] == 11\n",
    "\n",
    "INTERCEPT = 0.0\n",
    "SLOPE = 0.83\n",
    "\n",
    "CVDF[\"reco_e\"] = (CVDF[\"shr_energy_tot_cali\"] + INTERCEPT) / SLOPE + CVDF[\"trk_energy_tot\"] #for showers\n",
    "\n",
    "#'''\n",
    "\n",
    "#QUERY = \"nslice == 1\"\n",
    "\n",
    "\n",
    "#CVDF = CVDF.query(QUERY)\n",
    "\n",
    "print ('there are %i CV events'%(CVDF.shape[0]))\n",
    "\n",
    "DETSYS_SAMPLE_V = []\n",
    "\n",
    "for i,N in enumerate(DETVAR_N_V):\n",
    "    \n",
    "    #if (i >= 6):\n",
    "    #    continue\n",
    "    \n",
    "    VAR = uproot.open(ls.ntuple_path+DETVAR_S_V[i])[fold][tree]\n",
    "    VARDF = VAR.pandas.df(variables, flatten=False)\n",
    "    \n",
    "    VARDF['identifier'] = VARDF['run']*100000 + VARDF['evt']\n",
    "    \n",
    "    VARDF.loc[ VARDF['weightSplineTimesTune'] <= 0, 'weightSplineTimesTune' ] = 1.\n",
    "    VARDF.loc[ VARDF['weightSplineTimesTune'] == np.inf, 'weightSplineTimesTune' ] = 1.\n",
    "    VARDF.loc[ VARDF['weightSplineTimesTune'] > 100, 'weightSplineTimesTune' ] = 1.\n",
    "    VARDF.loc[ np.isnan(VARDF['weightSplineTimesTune']) == True, 'weightSplineTimesTune' ] = 1.\n",
    "\n",
    "    #'''\n",
    "    trk_llr_pid_v = VAR.array('trk_llr_pid_score_v')\n",
    "    trk_energy_proton_v = VAR.array('trk_energy_proton_v')\n",
    "    trk_calo_energy_y_v = VAR.array('trk_calo_energy_y_v')\n",
    "    trk_id = VAR.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    trk_energy_proton_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_energy_proton_v,trk_id)])\n",
    "    trk_calo_energy_y_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_calo_energy_y_v,trk_id)])\n",
    "    VARDF['trkpid'] = trk_llr_pid_v_sel\n",
    "    VARDF['protonenergy'] = trk_energy_proton_sel\n",
    "    VARDF['trackcaloenergy'] = trk_calo_energy_y_sel\n",
    "    VARDF['subcluster'] = VARDF['shrsubclusters0'] + VARDF['shrsubclusters1'] + VARDF['shrsubclusters2']\n",
    "    VARDF['trkfit'] = VARDF['shr_tkfit_npointsvalid'] / VARDF['shr_tkfit_npoints']\n",
    "    VARDF['anglediff_Y'] = np.abs(VARDF['secondshower_Y_dir']-VARDF['shrclusdir2'])\n",
    "\n",
    "    VARDF['shr_tkfit_2cm_nhits_tot'] = (VARDF['shr_tkfit_2cm_nhits_Y']+VARDF['shr_tkfit_2cm_nhits_U']+VARDF['shr_tkfit_2cm_nhits_V'])\n",
    "    VARDF['shr_tkfit_2cm_dedx_avg'] = (VARDF['shr_tkfit_2cm_nhits_Y']*VARDF['shr_tkfit_2cm_dedx_Y'] + VARDF['shr_tkfit_2cm_nhits_U']*VARDF['shr_tkfit_2cm_dedx_U'] + VARDF['shr_tkfit_2cm_nhits_V']*VARDF['shr_tkfit_2cm_dedx_V'])/VARDF['shr_tkfit_2cm_nhits_tot']\n",
    "    VARDF['shr_tkfit_gap10_nhits_tot'] = (VARDF['shr_tkfit_gap10_nhits_Y']+VARDF['shr_tkfit_gap10_nhits_U']+VARDF['shr_tkfit_gap10_nhits_V'])\n",
    "    VARDF['shr_tkfit_gap10_dedx_avg'] = (VARDF['shr_tkfit_gap10_nhits_Y']*VARDF['shr_tkfit_gap10_dedx_Y'] + VARDF['shr_tkfit_gap10_nhits_U']*VARDF['shr_tkfit_gap10_dedx_U'] + VARDF['shr_tkfit_gap10_nhits_V']*VARDF['shr_tkfit_gap10_dedx_V'])/VARDF['shr_tkfit_gap10_nhits_tot']\n",
    "\n",
    "    VARDF[\"reco_e\"] = (VARDF[\"shr_energy_tot_cali\"] + INTERCEPT) / SLOPE + VARDF[\"trk_energy_tot\"]\n",
    "\n",
    "    VARDF['trk_p_quality_v'] = (VARDF['trk_mcs_muon_mom_v']-VARDF['trk_range_muon_mom_v'])/VARDF['trk_range_muon_mom_v']\n",
    "    VARDF['trk_costheta_v'] = VARDF['trk_theta_v'].apply(lambda x: np.cos(x))\n",
    "    VARDF['reco_nu_e_range'] = VARDF[\"trk_energy_muon\"] + (VARDF[\"trk_energy_tot\"] - VARDF[\"trk_energy\"]) + M_mu\n",
    "    VARDF['reco_muon_e_range'] = VARDF[\"trk_energy_muon\"] + M_mu\n",
    "    \n",
    "    VARDF[\"is_signal\"] = VARDF[\"category\"] == 11 \n",
    "    #'''\n",
    "    \n",
    "    #VARDF = VARDF.query(QUERY)\n",
    "    \n",
    "    INT = pd.merge(CVDF, VARDF, how='inner', on=['identifier'],suffixes=('_CV', '_VAR'))\n",
    "\n",
    "    print ('intersection for %15s variation has %i events'%(N,INT.shape[0]))\n",
    "    \n",
    "    DETSYS_SAMPLE_V.append(INT)\n",
    "    \n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#all the code necessary to make the track-level cuts\n",
    "###################################################\n",
    "def _apply_track_cuts(df,variable,track_cuts,mask,fix=''):\n",
    "    #need to do this fancy business with the apply function to make masks\n",
    "    #fix is either \"CV\" or \"_VAR\"\n",
    "    for (var,op,val) in track_cuts:\n",
    "        var = var + fix\n",
    "        if type(op) == list:\n",
    "            #this means treat two conditions in an 'or' fashion\n",
    "            or_mask1 = df[var].apply(lambda x: eval(\"x{}{}\".format(op[0],val[0])))#or condition 1\n",
    "            or_mask2 = df[var].apply(lambda x: eval(\"x{}{}\".format(op[1],val[1])))#or condition 2\n",
    "            mask *= (or_mask1 + or_mask2) #just add the booleans\n",
    "        else:\n",
    "            mask *= df[var].apply(lambda x: eval(\"x{}{}\".format(op,val))) #layer on each cut mask\n",
    "    VARS = (df[variable]*mask).apply(lambda x: x[x != False]) #apply mask\n",
    "    VARS = VARS[VARS.apply(lambda x: len(x) > 0)] #clean up empty slices\n",
    "    #fix list comprehension issue for non '_v' variables\n",
    "    if \"_v_\" not in variable:\n",
    "        VARS = VARS.apply(lambda x: x[0])\n",
    "\n",
    "    return VARS, mask\n",
    "\n",
    "def _select_longest(df, VARS, mask,fix):\n",
    "    trk_lens = (df['trk_len_v'+fix]*mask).apply(lambda x: x[x != False])#apply mask to track lengths\n",
    "    trk_lens = trk_lens[trk_lens.apply(lambda x: len(x) > 0)]#clean up empty slices\n",
    "    longest_mask = trk_lens.apply(lambda x: x == x[list(x).index(max(x))])#identify longest\n",
    "    VARS = (VARS*longest_mask).apply(lambda x: x[x!=False])#apply mask\n",
    "    VARS = VARS[VARS.apply(lambda x: len(x) > 0)]#clean up empty slices\n",
    "    if len(VARS.iloc[0]) == 1:\n",
    "        VARS = VARS.apply(lambda x: x[0] if len(x)>0 else -999)#expect values, not lists, for each event\n",
    "    else:\n",
    "        raise ValueError(\n",
    "        \"There are more than one longest track per slice\")\n",
    "\n",
    "    return VARS, longest_mask\n",
    "\n",
    "def _selection(variable, sample, query=\"selected==1\", extra_cut=None, track_cuts=None, select_longest=True, fix='',return_fix=None):\n",
    "    #fix up variable and return variable\n",
    "    variable = variable + fix\n",
    "    if return_fix == None:\n",
    "        return_variable = variable\n",
    "    else:\n",
    "        return_variable = variable + return_fix\n",
    "        \n",
    "    sel_query = query\n",
    "    #check fix\n",
    "    if fix != '' and fix[0] != '_':\n",
    "        fix = '_' + fix\n",
    "    if fix not in ['','_CV','_VAR']:\n",
    "        raise ValueError(\"'fix' = {} is not a valid option \\n Choose '_CV' or '_VAR'\")\n",
    "    \n",
    "    if extra_cut is not None:\n",
    "        sel_query += \"& %s\" % extra_cut\n",
    "\n",
    "    df = sample.copy().query(sel_query)\n",
    "\n",
    "    track_cuts_mask = df['trk_score_v{}'.format(fix)].apply(lambda x: x == x) #all-True mask\n",
    "    if track_cuts is not None:\n",
    "        VARS, track_cuts_mask = _apply_track_cuts(df,variable,track_cuts,track_cuts_mask,fix=fix)\n",
    "    else:\n",
    "        VARS = df[variable]\n",
    "    #vars is now a Series object that passes all the cuts\n",
    "\n",
    "    if \"_v_\" in variable and select_longest:\n",
    "        VARS, longest_mask = _select_longest(df, VARS, track_cuts_mask,fix=fix)\n",
    "        \n",
    "    return VARS.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def COVARIANCE(n_cv,n_var):\n",
    "    cov = np.empty([len(n_cv), len(n_cv)])\n",
    "    cov.fill(0)\n",
    "\n",
    "    for i in range(len(n_cv)):\n",
    "        for j in range(len(n_cv)):\n",
    "            cov[i][j] += (n_var[i] - n_cv[i])*(n_var[j] - n_cv[j])\n",
    "            #if cov[i][j] == 0:\n",
    "            #    print(\"cov_\",i,j)\n",
    "            #    print(n_var[i],n_cv[i],n_var[j],n_cv[j])\n",
    "            \n",
    "    frac_cov = np.empty([len(n_cv), len(n_cv)])\n",
    "    corr = np.empty([len(n_cv), len(n_cv)])\n",
    "\n",
    "    for i in range(len(n_cv)):\n",
    "        for j in range(len(n_cv)):\n",
    "            frac_cov[i][j] =  cov[i][j] / (n_cv[i] * n_cv[j])\n",
    "            corr[i][j] = cov[i][j] / np.sqrt(cov[i][i] * cov[j][j])\n",
    "    return cov,frac_cov,corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Export sqrt(diag(frac_cov)) to .csv file\n",
    "# Note SAVEPATH /syst/\n",
    "########################################\n",
    "\n",
    "#reload in case of changes\n",
    "importlib.reload(ls)\n",
    "\n",
    "#track_cuts = None\n",
    "\n",
    "\n",
    "\n",
    "VARIABLE = \"trk_costheta_v\"\n",
    "BINS = np.linspace(-1,1,26)\n",
    "\n",
    "tag = '_fullsel'\n",
    "\n",
    "SAVEPATH = ls.main_path+\"detsys\\\\csv\\\\\"\n",
    "#if tag:\n",
    "#    SAVEPATH += tag[1:]+\"\\\\\"\n",
    "if not os.path.exists(SAVEPATH):\n",
    "    os.makedirs(SAVEPATH)\n",
    "\n",
    "    \n",
    "#use bins to create index labels\n",
    "index_labels = []\n",
    "for b,bin_edge in enumerate(BINS):\n",
    "    if b == len(BINS)-1: break\n",
    "    index_labels.append(\"{}-{}\".format(round(bin_edge,2),round(BINS[b+1],2)))\n",
    "    \n",
    "#make DataFrame that will eventually be exported\n",
    "ERRS_DF = pd.DataFrame(index=index_labels)\n",
    "\n",
    "#make sure you have the right parameters set\n",
    "print(\"QUERY: {}\".format(QUERY))\n",
    "print(\"track_cuts: {}\".format(track_cuts))\n",
    "print(\"using tag: {}\".format(tag))\n",
    "\n",
    "#loop through all samples\n",
    "for i,df_perm in enumerate(DETSYS_SAMPLE_V):\n",
    "    print(\"starting {}...\".format(DETVAR_N_V[i]))\n",
    "        \n",
    "    df = df_perm.copy()\n",
    "\n",
    "    VARS_CV = _selection(VARIABLE,\n",
    "                        df,QUERY,\n",
    "                        track_cuts = track_cuts,\n",
    "                        select_longest = True,\n",
    "                        fix = '_CV')\n",
    "    VARS_VAR = _selection(VARIABLE,\n",
    "                        df,QUERY,\n",
    "                        track_cuts = track_cuts,\n",
    "                        select_longest = True,\n",
    "                        fix = '_VAR')\n",
    "\n",
    "    bc = 0.5*(BINS[1:]+BINS[:-1])\n",
    "    n_cv,_ = np.histogram(VARS_CV,bins=BINS)\n",
    "    n_var,_ = np.histogram(VARS_VAR,bins=BINS)\n",
    "    \n",
    "    cov,frac_cov,corr = COVARIANCE(n_cv,n_var)\n",
    "    error = np.sqrt(np.diag(frac_cov))\n",
    "    \n",
    "    #layer these results onto the dataframe\n",
    "    ERRS_DF[DETVAR_N_V[i]] = np.around(error, decimals=3)\n",
    "    \n",
    "#add in some calculated columns\n",
    "samples = list(ERRS_DF.keys())\n",
    "ERRS_DF['sum'] = np.sqrt((ERRS_DF[samples]**2).sum(axis=1))\n",
    "samples.remove(\"Recomb\")\n",
    "ERRS_DF['sum_noRecomb'] = np.sqrt((ERRS_DF[samples]**2).sum(axis=1))\n",
    "samples.append(\"Recomb\")\n",
    "samples.remove(\"WireMod dEdX\")\n",
    "ERRS_DF['sum_nodEdX'] = np.sqrt((ERRS_DF[samples]**2).sum(axis=1))\n",
    "\n",
    "#ERRS_DF.to_csv(SAVEPATH+'{}_{}{}_{}-{}-{}.csv'.format(VARIABLE,date_time,tag,BINS[0],BINS[-1],len(BINS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Make many plots with one VAR sample\n",
    "########################################\n",
    "importlib.reload(ls)\n",
    "\n",
    "#potentially useful values\n",
    "AVx = [-1.55,254.8]\n",
    "AVy = [-115.53, 117.47]\n",
    "AVz = [0.1, 1036.9]\n",
    "M_mu = 0.105 #GeV/c\n",
    "\n",
    "track_cuts = [\n",
    "    ('trk_sce_start_x_v', '>', FVx[0]),\n",
    "    ('trk_sce_start_x_v', '<', FVx[1]),\n",
    "    ('trk_sce_start_y_v', '>', FVy[0]),\n",
    "    ('trk_sce_start_y_v', '<', FVy[1]),\n",
    "    ('trk_sce_start_z_v', '>', FVz[0]),\n",
    "    ('trk_sce_start_z_v', '<', FVz[1]),\n",
    "    ('trk_sce_end_x_v', '>', FVx[0]),\n",
    "    ('trk_sce_end_x_v', '<', FVx[1]),\n",
    "    ('trk_sce_end_y_v', '>', FVy[0]),\n",
    "    ('trk_sce_end_y_v', '<', FVy[1]),\n",
    "    ('trk_sce_end_z_v', '>', FVz[0]),\n",
    "    ('trk_sce_end_z_v', '<', FVz[1]),\n",
    "    ('trk_p_quality_v', '>', -0.5),\n",
    "    ('trk_p_quality_v', '<', 0.5),\n",
    "    ('trk_llr_pid_score_v', '>', 0.2),\n",
    "    ('trk_score_v', '>', 0.8),\n",
    "    ('trk_len_v', '>', 10),\n",
    "    ('pfp_generation_v', '==', 2),\n",
    "    ('trk_distance_v', '<', 4)\n",
    "]   \n",
    "track_cuts = None\n",
    "\n",
    "variables = ['reco_nu_e_range', 'reco_muon_e_range',\n",
    "            'trk_llr_pid_score_v',\n",
    "            'reco_nu_vtx_sce_x','reco_nu_vtx_sce_y','reco_nu_vtx_sce_z']\n",
    "titles = ['Reconstructed Neutrino Energy [GeV]','Reconstructed Muon Energy [GeV]',\n",
    "         'Log-Likelihood PID Score',\n",
    "          \"Reconstructed Vertex X [cm]\",\"Reconstructed Vertex Y [cm]\",\"Reconstructed Vertex Z [cm]\"]\n",
    "binss = [np.linspace(0.15,1.55,15),np.linspace(0.15,1.2,15),\n",
    "         np.linspace(-1,1,26),\n",
    "         np.linspace(FVx[0],FVx[1],26),np.linspace(FVy[0],FVy[1],26),np.linspace(FVz[0],FVz[1],26)]\n",
    "\n",
    "variables = ['reco_nu_e_range']\n",
    "titles = ['Reconstructed Range-Based Neutrino Energy [GeV]']\n",
    "binss = [np.linspace(M_mu+0.01,1.55,26)]\n",
    "\n",
    "#select variation sample\n",
    "idx = DETVAR_N_V.index('SCE') #just looking at one variation \n",
    "df = DETSYS_SAMPLE_V[idx].copy()  #avoid making changed to source\n",
    "tag = None\n",
    "\n",
    "print(\"QUERY: {}\".format(QUERY))\n",
    "print(\"track_cuts: {}\".format(track_cuts))\n",
    "for VARIABLE,TITLE,BINS in  zip(variables,titles,binss):    \n",
    "    print(\"{}\\t{}\\t{}\".format(VARIABLE,TITLE,BINS))\n",
    "    \n",
    "    SAVEPATH = ls.main_path+\"detsys\\\\plots\\\\\"\n",
    "    if tag:\n",
    "        SAVEPATH += tag[1:]+'\\\\'\n",
    "    if not os.path.exists(SAVEPATH):\n",
    "        os.makedirs(SAVEPATH)\n",
    "\n",
    "        \n",
    "    ################################\n",
    "    # CV-VAR histogram comparison\n",
    "    fig = plt.figure(figsize=(7,5))\n",
    "    \n",
    "    #get queried array of the variable\n",
    "    VARS_CV = _selection(VARIABLE,\n",
    "                        df,QUERY,\n",
    "                        track_cuts = track_cuts,\n",
    "                        select_longest = True,\n",
    "                        fix = '_CV')\n",
    "    VARS_VAR = _selection(VARIABLE,\n",
    "                        df,QUERY,\n",
    "                        track_cuts = track_cuts,\n",
    "                        select_longest = True,\n",
    "                        fix = '_VAR')\n",
    "\n",
    "    WEIGHTS_CV = _selection('weightSplineTimesTune',\n",
    "                            df,QUERY,\n",
    "                            track_cuts = track_cuts,\n",
    "                            select_longest = True,\n",
    "                            fix = '_CV')\n",
    "    WEIGHTS_VAR = _selection('weightSplineTimesTune',\n",
    "                            df,QUERY,\n",
    "                            track_cuts = track_cuts,\n",
    "                            select_longest = True,\n",
    "                            fix = '_VAR')\n",
    "\n",
    "    #get number of entries in each bin for each sample. and plot hists\n",
    "    n_cv, bins, p = plt.hist(VARS_CV ,bins=BINS,histtype='step',lw=2,color='k',\\\n",
    "             label='CV',weights=WEIGHTS_CV)\n",
    "    n_var, bins, p = plt.hist(VARS_VAR,bins=BINS,histtype='step',lw=2,color='r',\\\n",
    "             label='var : %s'%DETVAR_N_V[idx],weights=WEIGHTS_VAR)\n",
    "\n",
    "    bc = 0.5*(bins[1:]+bins[:-1]) #bin centers\n",
    "\n",
    "    cov,frac_cov,corr = COVARIANCE(n_cv,n_var) #calculate various matrices\n",
    "    error = np.sqrt(np.diag(frac_cov)) #systematic error is this\n",
    "    #incorporate errors from fractional covariance matrix\n",
    "    plt.bar(bc,height=2*(error)*n_cv,bottom=n_cv-(error)*n_cv,width=bc[1]-bc[0], \n",
    "            edgecolor='gray',color='None',lw=2)\n",
    "    plt.xlabel(TITLE)\n",
    "    plt.ylabel('Num. Entries')\n",
    "    plt.ylim(0,plt.gca().get_ylim()[1]*1.5)\n",
    "    plt.legend(fontsize=16,loc=1)\n",
    "    plt.show()\n",
    "    plt.tight_layout()\n",
    "    #fig.savefig(SAVEPATH+VARIABLE+\"_\"+date_time+\"_{}{}.pdf\".format(DETVAR_N_V[idx],tag))\n",
    "\n",
    "    #########################################\n",
    "    #Show the variance of the variable\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    \n",
    "    #apply _CV cuts only for equal sized arrays\n",
    "    VARS_VAR_CV = _selection(VARIABLE,\n",
    "                        df,QUERY,\n",
    "                        track_cuts = track_cuts,\n",
    "                        select_longest = True,\n",
    "                        fix = '_CV',\n",
    "                        return_fix = '_VAR')\n",
    "    #trim the out of range bits\n",
    "    mask_inrange = VARS_CV<BINS[-1]\n",
    "    mask_inrange *= VARS_CV>BINS[0]\n",
    "    mask_inrange *= VARS_VAR_CV<BINS[-1]\n",
    "    mask_inrange *= VARS_VAR_CV>BINS[0]\n",
    "    #plot variance\n",
    "    plt.hist2d(VARS_CV[mask_inrange],VARS_VAR_CV[mask_inrange],bins=(BINS.size-1,BINS.size-1))#,norm=LogNorm())\n",
    "    plt.xlabel('%s [CV]'%TITLE)\n",
    "    plt.ylabel('%s [VAR]'%TITLE)\n",
    "    plt.title('variation : %s'%DETVAR_N_V[idx],fontsize=16)\n",
    "    plt.plot(BINS,BINS,'r--',lw=2)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    #fig.savefig(SAVEPATH+VARIABLE+\"_\"+date_time+\"_{}_variation{}.pdf\".format(DETVAR_N_V[idx],tag))\n",
    "\n",
    "    ####################################\n",
    "    # Make covariance plots\n",
    "    fig, axes = plt.subplots(2, 1,figsize=(10,12))\n",
    "    #start with fractional covariance\n",
    "    ax = axes[0]\n",
    "    #plot fractional covariance\n",
    "    pos = ax.imshow(frac_cov, origin='lower', cmap='viridis')#,vmin=-0.1,vmax=0.1) #be consistent when comparing multiple plots\n",
    "    ax.set_title(\"Fractional covariance matrix : %s\"%DETVAR_N_V[idx])\n",
    "    ax.set_ylabel(\"Bin number\")\n",
    "    ax.set_xlabel(\"Bin number\")\n",
    "    \n",
    "    # Add the text\n",
    "    # Limits for the extent\n",
    "    x_start = 0\n",
    "    x_end = len(n_cv)#-1\n",
    "    y_start = 0\n",
    "    y_end = len(n_cv)#-1\n",
    "    size = len(n_cv)#-1\n",
    "    jump_x = (x_end - x_start) / (2.0 * size)\n",
    "    jump_y = (y_end - y_start) / (2.0 * size)\n",
    "    x_positions = np.linspace(start=x_start, stop=x_end, num=size, endpoint=False)\n",
    "    y_positions = np.linspace(start=y_start, stop=y_end, num=size, endpoint=False)\n",
    "    #print the value of error on the diagonal\n",
    "    for x_index, x in enumerate(x_positions):\n",
    "        #for x_index, x in enumerate(x_positions):\n",
    "        ERR = frac_cov[x_index, x_index]\n",
    "        #label = \"{:.2f}\\n{} {}\".format(100.*np.sqrt(ERR),int(round(n_cv[x_index])),int(round(n_var[x_index])))\n",
    "        label = \"{:.2f}\".format(100.*np.sqrt(ERR))\n",
    "        text_x = x #+ jump_x\n",
    "        text_y = x #+ jump_y\n",
    "        if (np.abs(ERR) > 0.05):\n",
    "            ax.text(text_x, text_y, label, color='black', ha='center', va='center',fontsize=8)\n",
    "        else:\n",
    "            ax.text(text_x, text_y, label, color='white', ha='center', va='center',fontsize=8)\n",
    "    fig.colorbar(pos, ax=ax)\n",
    "    \n",
    "    #start on correlation matrix\n",
    "    ax = axes[1]\n",
    "    ax.set_title(\"Correlation matrix\")\n",
    "    pos = ax.imshow(corr, origin='lower')\n",
    "    ax.set_ylabel(\"Bin number\")\n",
    "    ax.set_xlabel(\"Bin number\")\n",
    "    fig.colorbar(pos, ax = ax)\n",
    "    plt.tight_layout()\n",
    "    #fig.savefig(SAVEPATH+VARIABLE+\"_\"+date_time+\"_{}_corrs{}.pdf\".format(DETVAR_N_V[idx],tag))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Loop over all systematic variations\n",
    "# ...and over several varibles\n",
    "#############################################\n",
    "importlib.reload(ls)\n",
    "\n",
    "#have to edit code to just accept one of these at a time\n",
    "VARIABLE = \"trk_p_quality_v\"\n",
    "TITLE = \"MCS Consistency\"\n",
    "BINS = np.linspace(-2,5,15)\n",
    "\n",
    "VARIABLE = \"trk_len_v\"\n",
    "TITLE = \"Track Length, Muon Candidate [cm]\"\n",
    "BINS = np.linspace(0,500,20)\n",
    "\n",
    "VARIABLE = \"topological_score\"\n",
    "TITLE = \"Topological Score\"\n",
    "BINS = np.linspace(0,1,25)\n",
    "\n",
    "#do this for single var...below is multivar\n",
    "variables = [VARIABLE]\n",
    "titles = [TITLE]\n",
    "binss = [BINS]\n",
    "\n",
    "\n",
    "track_cuts = [\n",
    "    ('trk_sce_start_x_v', '>', FVx[0]),\n",
    "    ('trk_sce_start_x_v', '<', FVx[1]),\n",
    "    ('trk_sce_start_y_v', '>', FVy[0]),\n",
    "    ('trk_sce_start_y_v', '<', FVy[1]),\n",
    "    ('trk_sce_start_z_v', '>', FVz[0]),\n",
    "    ('trk_sce_start_z_v', '<', FVz[1]),\n",
    "    ('trk_sce_end_x_v', '>', FVx[0]),\n",
    "    ('trk_sce_end_x_v', '<', FVx[1]),\n",
    "    ('trk_sce_end_y_v', '>', FVy[0]),\n",
    "    ('trk_sce_end_y_v', '<', FVy[1]),\n",
    "    ('trk_sce_end_z_v', '>', FVz[0]),\n",
    "    ('trk_sce_end_z_v', '<', FVz[1]),\n",
    "    ('trk_p_quality_v', '>', -0.5),\n",
    "    ('trk_p_quality_v', '<', 0.5),\n",
    "    ('trk_llr_pid_score_v', '>', 0.2),\n",
    "    ('trk_score_v', '>', 0.8),\n",
    "    ('trk_len_v', '>', 10),\n",
    "    ('pfp_generation_v', '==', 2),\n",
    "    ('trk_distance_v', '<', 4)\n",
    "]   \n",
    "track_cuts = None\n",
    "\n",
    "# multivariate study\n",
    "\"\"\"\n",
    "variables = ['reco_nu_e_range', 'reco_muon_e_range',\n",
    "            'trk_llr_pid_score_v',\n",
    "            ]\n",
    "titles = ['Reconstructed Neutrino Energy [GeV]','Reconstructed Muon Energy [GeV]',\n",
    "         'Log-Likelihood PID Score',\n",
    "          ]\n",
    "binss = [np.linspace(0.15,1.55,15),np.linspace(0.15,1.2,15),\n",
    "         np.linspace(-1,1,26),\n",
    "         ]\n",
    "\"\"\"\n",
    "\n",
    "tag = '_SCEstudy' #will probably help define save path\n",
    "\n",
    "for VARIABLE,TITLE,BINS in  zip(variables,titles,binss):\n",
    "    print(\"\\n\\nDOING {} NOW!!!!!!\\n\".format(VARIABLE))\n",
    "    \n",
    "    SAVEPATH = ls.main_path+\"detsys\\\\plots\\\\\"\n",
    "    SAVEPATH += '{}\\\\'.format(VARIABLE)\n",
    "    if tag:\n",
    "        SAVEPATH += tag[1:]+'\\\\'\n",
    "    if not os.path.exists(SAVEPATH):\n",
    "        os.makedirs(SAVEPATH)\n",
    "\n",
    "    for i,df_perm in enumerate(DETSYS_SAMPLE_V):\n",
    "        print(\"starting {}...\".format(DETVAR_N_V[i]))\n",
    "        df = df_perm.copy()\n",
    "        idx = i#+6 #\n",
    "\n",
    "        ################################\n",
    "        # CV-VAR histogram comparison \n",
    "        fig = plt.figure(figsize=(7,5))\n",
    "        #get queried array of the variable\n",
    "        VARS_CV = _selection(VARIABLE,\n",
    "                            df,QUERY,\n",
    "                            track_cuts = track_cuts,\n",
    "                            select_longest = True,\n",
    "                            fix = '_CV')\n",
    "        VARS_VAR = _selection(VARIABLE,\n",
    "                            df,QUERY,\n",
    "                            track_cuts = track_cuts,\n",
    "                            select_longest = True,\n",
    "                            fix = '_VAR')\n",
    "        \n",
    "        WEIGHTS_CV = _selection('weightSplineTimesTune',\n",
    "                                df,QUERY,\n",
    "                                track_cuts = track_cuts,\n",
    "                                select_longest = True,\n",
    "                                fix = '_CV')\n",
    "        WEIGHTS_VAR = _selection('weightSplineTimesTune',\n",
    "                                df,QUERY,\n",
    "                                track_cuts = track_cuts,\n",
    "                                select_longest = True,\n",
    "                                fix = '_VAR')\n",
    "        #get n entries per bin\n",
    "        n_cv, bins, p = plt.hist(VARS_CV ,bins=BINS,histtype='step',lw=2,color='k',\\\n",
    "                 label='CV',weights=WEIGHTS_CV)\n",
    "        n_var, bins, p = plt.hist(VARS_VAR,bins=BINS,histtype='step',lw=2,color='r',\\\n",
    "                 label='var : %s'%DETVAR_N_V[idx],weights=WEIGHTS_VAR)\n",
    "        #calc bin centers\n",
    "        bc = 0.5*(bins[1:]+bins[:-1])\n",
    "        #make covariance and correlation calculations\n",
    "        cov,frac_cov,corr = COVARIANCE(n_cv,n_var)\n",
    "        #get and plot the systematic error with these cuts + variable\n",
    "        error = np.sqrt(np.diag(frac_cov))\n",
    "        plt.bar(bc,height=2*(error)*n_cv,bottom=n_cv-(error)*n_cv,width=bc[1]-bc[0] ,\\\n",
    "                edgecolor='gray',color='None',lw=2)\n",
    "        plt.xlabel(TITLE)\n",
    "        plt.ylabel('Num. Entries')\n",
    "        plt.ylim(0,plt.gca().get_ylim()[1]*1.5)\n",
    "        plt.legend(fontsize=16,loc=1)\n",
    "        plt.show()\n",
    "        #fig.savefig(SAVEPATH+VARIABLE+\"_\"+date_time+\"_{}{}.pdf\".format(DETVAR_N_V[idx],tag))\n",
    "\n",
    "        #####################################################\n",
    "        #Show the variance of the variable\n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "        #apply _CV cuts only to get equal sized arrays\n",
    "        VARS_VAR_CV = _selection(VARIABLE,\n",
    "                            df,QUERY,\n",
    "                            track_cuts = track_cuts,\n",
    "                            select_longest = True,\n",
    "                            fix = '_CV',\n",
    "                            return_fix = '_VAR') #VAR events that correspond to CV events that pass all cuts\n",
    "        mask_inrange = VARS_CV<BINS[-1]\n",
    "        mask_inrange *= VARS_CV>BINS[0]\n",
    "        mask_inrange *= VARS_VAR_CV<BINS[-1]\n",
    "        mask_inrange *= VARS_VAR_CV>BINS[0]\n",
    "        plt.hist2d(VARS_CV[mask_inrange],VARS_VAR_CV[mask_inrange],bins=(BINS.size-1,BINS.size-1))#,norm=LogNorm())\n",
    "        plt.xlabel('%s [CV]'%TITLE)\n",
    "        plt.ylabel('%s [VAR]'%TITLE)\n",
    "        plt.title('variation : %s'%DETVAR_N_V[idx],fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.plot(BINS,BINS,'r--',lw=2)\n",
    "        plt.colorbar()\n",
    "        #fig.savefig(SAVEPATH+VARIABLE+\"_\"+date_time+\"_{}_variation{}.pdf\".format(DETVAR_N_V[idx],tag))\n",
    "\n",
    "        ########################################\n",
    "        # do correlation and frac-covariance plot\n",
    "        fig, axes = plt.subplots(2, 1,figsize=(10,12))\n",
    "        #start with fractional covariance\n",
    "        ax = axes[0]\n",
    "        pos = ax.imshow(frac_cov, origin='lower', cmap='viridis')#,vmin=-0.1,vmax=0.1)\n",
    "        ax.set_title(\"Fractional covariance matrix : %s\"%DETVAR_N_V[idx])\n",
    "        ax.set_ylabel(\"Bin number\")\n",
    "        ax.set_xlabel(\"Bin number\")\n",
    "        \n",
    "        # Add text for errors on diagonal of frac_covariance\n",
    "        # Limits for the extent\n",
    "        x_start = 0\n",
    "        x_end = len(n_cv)#-1\n",
    "        y_start = 0\n",
    "        y_end = len(n_cv)#-1\n",
    "        size = len(n_cv)#-1\n",
    "        jump_x = (x_end - x_start) / (2.0 * size)\n",
    "        jump_y = (y_end - y_start) / (2.0 * size)\n",
    "        x_positions = np.linspace(start=x_start, stop=x_end, num=size, endpoint=False)\n",
    "        y_positions = np.linspace(start=y_start, stop=y_end, num=size, endpoint=False)\n",
    "        for x_index, x in enumerate(x_positions):\n",
    "            #for x_index, x in enumerate(x_positions):\n",
    "            ERR = frac_cov[x_index, x_index]\n",
    "            #label = \"{:.2f}\\n{} {}\".format(100.*np.sqrt(ERR),int(round(n_cv[x_index])),int(round(n_var[x_index])))\n",
    "            label = \"{:.2f}\".format(100.*np.sqrt(ERR))\n",
    "            text_x = x #+ jump_x\n",
    "            text_y = x #+ jump_y\n",
    "            if (np.abs(ERR) > 0.05):\n",
    "                ax.text(text_x, text_y, label, color='black', ha='center', va='center',fontsize=8)\n",
    "            else:\n",
    "                ax.text(text_x, text_y, label, color='white', ha='center', va='center',fontsize=8)\n",
    "\n",
    "        fig.colorbar(pos, ax=ax)\n",
    "        #start on correlation matrix\n",
    "        ax = axes[1]\n",
    "        ax.set_title(\"Correlation matrix\")\n",
    "        pos = ax.imshow(corr, origin='lower')\n",
    "        ax.set_ylabel(\"Bin number\")\n",
    "        ax.set_xlabel(\"Bin number\")\n",
    "        fig.colorbar(pos, ax = ax)\n",
    "        \n",
    "        #fig.savefig(SAVEPATH+VARIABLE+\"_\"+date_time+\"_{}_corrs{}.pdf\".format(DETVAR_N_V[idx],tag))\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Plotter.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
