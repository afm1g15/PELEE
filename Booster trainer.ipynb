{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import uproot\n",
    "import pickle\n",
    "import nue_booster\n",
    "import importlib\n",
    "importlib.reload(nue_booster)\n",
    "\n",
    "import awkward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import localSettings as ls\n",
    "print(ls.ntuple_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train both with RUN3 and RUN1?\n",
    "TRAINBOTH = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "VARLOAD = [\"shr_dedx_Y\", \"shr_bkt_pdg\", \"p\", \"pt\", \"selected\", \"nu_pdg\", \"shr_theta\",\n",
    "           \"slpdg\", \"trk_score_v\", \"backtracked_pdg\", # modified from shr_score_v\n",
    "           \"shr_pfp_id_v\", \"category\", \"shr_tkfit_dedx_Y\",\n",
    "    \"trk_energy_tot\", \"shr_hits_tot\", \"ccnc\", \"trk_chipr\",\n",
    "    \"trk_bkt_pdg\", \"hits_ratio\", \"n_tracks_contained\", \n",
    "    #\"crtveto\",\"crthitpe\",\"_closestNuCosmicDist\",\n",
    "    \"NeutrinoEnergy2\",\n",
    "    \"run\",\"sub\",\"evt\",\n",
    "    \"CosmicIP\",\n",
    "    \"nu_flashmatch_score\",\n",
    "    \"shrmoliereavg\",\"shrmoliererms\",\n",
    "    \"shr_tkfit_npointsvalid\",\"shr_tkfit_npoints\", # fitted vs. all hits for shower\n",
    "    \"shrclusfrac0\",\"shrclusfrac1\",\"shrclusfrac2\", # track-fitted hits / all hits\n",
    "    \"trkshrhitdist0\",\"trkshrhitdist1\",\"trkshrhitdist2\", # distance between track and shower in 2D\n",
    "    \"shrsubclusters0\",\"shrsubclusters1\",\"shrsubclusters2\", # number of sub-clusters in shower\n",
    "    \"trk_llr_pid_score_v\", # trk-PID score\n",
    "    \"pi0_gammadot\",\"pi0_mass_Y\",\"pi0_energy2_Y\", # pi0 tagger variables\n",
    "    \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "    \"nproton\", \"nu_e\", \"n_showers_contained\", \"shr_distance\", \"trk_distance\",\n",
    "    \"hits_y\", \"shr_pz\", \"shr_energy\", \"shr_dedx_U\", \"shr_dedx_V\", \"shr_phi\", \"trk_phi\", \"trk_theta\",\n",
    "    \"shr_tkfit_dedx_U\", \"shr_tkfit_dedx_V\", \"run\", \"sub\", \"evt\", \"nproton\", \"trk_pid_chipr_v\",\n",
    "    \"trk_len\", \"mc_pdg\", \"slnunhits\", \"slnhits\", \"shr_score\", \"trk_score\", \"trk_hits_tot\",\n",
    "    \"true_e_visible\", \"matched_E\", \"shr_bkt_E\", \"trk_bkt_E\", \"trk_energy\", \"tksh_distance\", \"tksh_angle\",\n",
    "    \"npi0\",\n",
    "    \"pi0_e\", \"shr_energy_tot_cali\", \"shr_dedx_Y_cali\", \"evnunhits\", \"nslice\", \"interaction\",\n",
    "    \"slclustfrac\", \"reco_nu_vtx_x\", \"reco_nu_vtx_y\", \"reco_nu_vtx_z\",\"contained_fraction\",\n",
    "    # second-shower tagging variables\n",
    "    \"secondshower_Y_nhit\",\"secondshower_Y_vtxdist\",\"secondshower_Y_dot\",\"secondshower_Y_dir\",\"shrclusdir2\",\n",
    "    \"secondshower_V_nhit\",\"secondshower_V_vtxdist\",\"secondshower_V_dot\",\"secondshower_V_dir\",\"shrclusdir1\",\n",
    "    \"secondshower_U_nhit\",\"secondshower_U_vtxdist\",\"secondshower_U_dot\",\"secondshower_U_dir\",\"shrclusdir0\",\n",
    "    #\n",
    "    \"shr_tkfit_gap10_dedx_U\",\"shr_tkfit_gap10_dedx_V\",\"shr_tkfit_gap10_dedx_Y\",# gap10 dedx\n",
    "    \"shr_tkfit_2cm_dedx_U\",\"shr_tkfit_2cm_dedx_V\",\"shr_tkfit_2cm_dedx_Y\"# 2cm dedx\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = \"nuselection\"\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "\n",
    "EXT3 = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_G_all_reco2.root'\n",
    "NU3  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run3_reco2_G_reco2.root'\n",
    "NUE3 = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2.root'\n",
    "NCPI03 = 'prodgenie_nc_pi0_uboone_overlay_mcc9.1_v08_00_00_26_run3_G_reco2.root'\n",
    "CCPI03 = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run3_G_reco2.root'\n",
    "\n",
    "EXT1 = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C_all_reco2.root'\n",
    "NU1  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run1_reco2_reco2.root'\n",
    "NUE1 = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2.root'\n",
    "NCPI01 = 'prodgenie_nc_pi0_uboone_overlay-v08_00_00_26_run1_reco2_reco2.root'\n",
    "CCPI01 = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run1_reco2.root'\n",
    "\n",
    "mc3 = uproot.open(ls.ntuple_path+NU3)[fold][tree]\n",
    "ncpi03 = uproot.open(ls.ntuple_path+NCPI03)[fold][tree]\n",
    "ccpi03 = uproot.open(ls.ntuple_path+CCPI03)[fold][tree]\n",
    "nue3 = uproot.open(ls.ntuple_path+NUE3)[fold][tree]\n",
    "ext3 = uproot.open(ls.ntuple_path+EXT3)[fold][tree]\n",
    "\n",
    "if (TRAINBOTH == True):\n",
    "    mc1 = uproot.open(ls.ntuple_path+NU1)[fold][tree]\n",
    "    ncpi01 = uproot.open(ls.ntuple_path+NCPI01)[fold][tree]\n",
    "    ccpi01 = uproot.open(ls.ntuple_path+CCPI01)[fold][tree]\n",
    "    nue1 = uproot.open(ls.ntuple_path+NUE1)[fold][tree]\n",
    "    ext1 = uproot.open(ls.ntuple_path+EXT1)[fold][tree]\n",
    "\n",
    "if (TRAINBOTH == True):\n",
    "    uproot_v = [mc3,ncpi03,ccpi03,nue3,ext3,mc1,ncpi01,ccpi01,nue1,ext1]\n",
    "else:\n",
    "    uproot_v = [mc3,ncpi03,ccpi03,nue3,ext3]\n",
    "    \n",
    "ncpi03 = ncpi03.pandas.df(VARLOAD + [\"weightSpline\"], flatten=False)\n",
    "ccpi03 = ccpi03.pandas.df(VARLOAD + [\"weightSpline\"], flatten=False)\n",
    "mc3 = mc3.pandas.df(VARLOAD + [\"weightSpline\"], flatten=False)\n",
    "nue3 = nue3.pandas.df(VARLOAD + [\"weightSpline\"], flatten=False)\n",
    "ext3 = ext3.pandas.df(VARLOAD, flatten=False)\n",
    "if (TRAINBOTH == True):\n",
    "    ncpi01 = ncpi01.pandas.df(VARLOAD + [\"weightSpline\"], flatten=False)\n",
    "    ccpi01 = ccpi01.pandas.df(VARLOAD + [\"weightSpline\"], flatten=False)\n",
    "    mc1 = mc1.pandas.df(VARLOAD + [\"weightSpline\"], flatten=False)\n",
    "    nue1 = nue1.pandas.df(VARLOAD + [\"weightSpline\"], flatten=False)\n",
    "    ext1 = ext1.pandas.df(VARLOAD, flatten=False)\n",
    "\n",
    "ext3[\"weightSpline\"] = 1\n",
    "if (TRAINBOTH == True):\n",
    "    ext1[\"weightSpline\"] = 1\n",
    "\n",
    "if (TRAINBOTH == True):\n",
    "    df_v = [mc3,ncpi03,ccpi03,nue3,ext3,mc1,ncpi01,ccpi01,nue1,ext1]\n",
    "else:\n",
    "    df_v = [mc3,ncpi03,ccpi03,nue3,ext3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some energy-related variables\n",
    "for i,df in enumerate(df_v):\n",
    "    df[\"reco_e\"] = (df[\"shr_energy_tot_cali\"] + 0.03) / 0.79 + df[\"trk_energy_tot\"]\n",
    "    df[\"reco_e_qe\"] = 0.938*((df[\"shr_energy\"]+0.030)/0.79)/(0.938 - ((df[\"shr_energy\"]+0.030)/0.79)*(1-np.cos(df[\"shr_theta\"])))\n",
    "    df[\"reco_e_rqe\"] = df[\"reco_e_qe\"]/df[\"reco_e\"]\n",
    "    # and the 2d angle difference\n",
    "    df['anglediff_Y'] = np.abs(df['secondshower_Y_dir']-df['shrclusdir2'])\n",
    "    df['anglediff_V'] = np.abs(df['secondshower_V_dir']-df['shrclusdir1'])\n",
    "    df['anglediff_U'] = np.abs(df['secondshower_U_dir']-df['shrclusdir0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get the LLR-PID value for the \"track candidate\" (proton for nue selection, muon for numu)\n",
    "# can be done for any variable\n",
    "# code from Giuseppe!\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "    df['trkfit'] = df['shr_tkfit_npointsvalid'] / df['shr_tkfit_npoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lee_bins = [0, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6, 0.8]\n",
    "#lee_scaling = [\n",
    "#    6.3744101, 6.3744101, 5.6455402, 3.7305500, 1.5091400, 1.0742800, 0.7540929,\n",
    "#    0.4763070, 0.1523270\n",
    "#]\n",
    "##lee_scaling = [1,1,1,1,1,1,1,1,1]\n",
    "#ncpi03[\"train_weight\"] = 1\n",
    "#ccpi03[\"train_weight\"] = 1\n",
    "#nue3[\"train_weight\"] = 0\n",
    "#mc3[\"train_weight\"] = 1\n",
    "#ext3[\"train_weight\"] = 1\n",
    "#if (TRAINBOTH == True):\n",
    "#    ncpi01[\"train_weight\"] = 1\n",
    "#    ccpi01[\"train_weight\"] = 1\n",
    "#    nue1[\"train_weight\"] = 0\n",
    "#    mc1[\"train_weight\"] = 1\n",
    "#    ext1[\"train_weight\"] = 1\n",
    "#for i, lee_bin in enumerate(lee_bins):\n",
    "#    if i == 0: continue\n",
    "#    nue3.loc[(nue3['nu_e'] > lee_bins[i-1]) & (nue3['nu_e'] < lee_bins[i]), 'train_weight'] = lee_scaling[i-1] * nue3['weightSpline']\n",
    "#    if (TRAINBOTH==True):\n",
    "#        nue1.loc[(nue1['nu_e'] > lee_bins[i-1]) & (nue1['nu_e'] < lee_bins[i]), 'train_weight'] = lee_scaling[i-1] * nue1['weightSpline']\n",
    "\n",
    "ncpi03[\"train_weight\"] = 1\n",
    "ccpi03[\"train_weight\"] = 1\n",
    "nue3[\"train_weight\"] = 1\n",
    "mc3[\"train_weight\"] = 2\n",
    "ext3[\"train_weight\"] = 2\n",
    "if (TRAINBOTH == True):\n",
    "    ncpi01[\"train_weight\"] = 1\n",
    "    ccpi01[\"train_weight\"] = 1\n",
    "    nue1[\"train_weight\"] = 1\n",
    "    mc1[\"train_weight\"] = 2\n",
    "    ext1[\"train_weight\"] = 2\n",
    "reco_bins = [0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2]\n",
    "reco_scaling = [5,5,5,2,2,2,1,1,1,1]\n",
    "for i,df in enumerate(df_v):\n",
    "    for i, reco_bin in enumerate(reco_bins):\n",
    "        if i == 0: continue\n",
    "        df.loc[(df['reco_e'] > reco_bins[i-1]) & (df['reco_e'] < reco_bins[i]), 'train_weight'] = df['train_weight']*reco_scaling[i-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncpi03[\"is_signal\"] = ncpi03[\"category\"] == 11\n",
    "ccpi03[\"is_signal\"] = ccpi03[\"category\"] == 11\n",
    "nue3[\"is_signal\"] = nue3[\"category\"] == 11\n",
    "mc3[\"is_signal\"] = mc3[\"category\"] == 11\n",
    "ext3[\"is_signal\"] = ext3[\"category\"] == 11\n",
    "if (TRAINBOTH == True):\n",
    "    ncpi01[\"is_signal\"] = ncpi01[\"category\"] == 11\n",
    "    ccpi01[\"is_signal\"] = ccpi01[\"category\"] == 11\n",
    "    nue1[\"is_signal\"] = nue1[\"category\"] == 11\n",
    "    mc1[\"is_signal\"] = mc1[\"category\"] == 11\n",
    "    ext1[\"is_signal\"] = ext1[\"category\"] == 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to be trained on\n",
    "TRAINVAR = [#\"n_showers_contained\",\n",
    "            \"shr_score\",\"tksh_distance\",\"tksh_angle\",\n",
    "            \"shr_tkfit_gap10_dedx_Y\",\"shr_tkfit_gap10_dedx_U\",\"shr_tkfit_gap10_dedx_V\",\n",
    "            \"shr_tkfit_2cm_dedx_Y\",\"shr_tkfit_2cm_dedx_U\",\"shr_tkfit_2cm_dedx_V\",\n",
    "            \"trkfit\",\"trkpid\",\"subcluster\",\"shrmoliereavg\",#\"shrmoliererms\",\n",
    "            \"trkshrhitdist2\",\"hits_ratio\",\n",
    "            \"secondshower_Y_nhit\",\"secondshower_Y_vtxdist\",\"secondshower_Y_dot\",\"anglediff_Y\",\n",
    "            #'secondshower_V_nhit','secondshower_V_vtxdist','secondshower_V_dot','anglediff_V',\n",
    "            #'secondshower_U_nhit','secondshower_U_vtxdist','secondshower_U_dot','anglediff_U',\n",
    "            #\"pi0_radlen1\",\"pi0_radlen2\",\"pi0_dedx2_fit_Y\",\n",
    "            #\"pi0_energy2_Y\",\"pi0_mass_Y\",\"pi0_gammadot\",\n",
    "            \"is_signal\",\"train_weight\",\"nu_e\"\n",
    "        ]\n",
    "#TRAINVAR = [\"tksh_angle\", \"shr_tkfit_dedx_Y\", \"shr_tkfit_dedx_U\", \"shr_tkfit_dedx_V\", \"n_showers_contained\", \n",
    "#            \"shr_score\", \"tksh_distance\", \"trkfit\", \"trkpid\", \"subcluster\", \"shrmoliereavg\", \"shrmoliererms\", \n",
    "#            \"trkshrhitdist2\", \"hits_ratio\",\n",
    "#            \"is_signal\",\"train_weight\",\"nu_e\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (ls.pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_mc3, test_mc3 = train_test_split(mc3, test_size=0.5, random_state=1990)\n",
    "train_ext3, test_ext3 = train_test_split(ext3, test_size=0.5, random_state=1990)\n",
    "train_nue3, test_nue3 = train_test_split(nue3, test_size=0.5, random_state=1990)\n",
    "train_ncpi03, test_ncpi03 = train_test_split(ncpi03, test_size=0.5, random_state=1990)\n",
    "train_ccpi03, test_ccpi03 = train_test_split(ccpi03, test_size=0.5, random_state=1990)\n",
    "if (TRAINBOTH == True):\n",
    "    train_mc1, test_mc1 = train_test_split(mc1, test_size=0.5, random_state=1990)\n",
    "    train_ext1, test_ext1 = train_test_split(ext1, test_size=0.5, random_state=1990)\n",
    "    train_nue1, test_nue1 = train_test_split(nue1, test_size=0.5, random_state=1990)\n",
    "    train_ncpi01, test_ncpi01 = train_test_split(ncpi01, test_size=0.5, random_state=1990)\n",
    "    train_ccpi01, test_ccpi01 = train_test_split(ccpi01, test_size=0.5, random_state=1990)\n",
    "\n",
    "# merge run1 and run3 samples\n",
    "if (TRAINBOTH == True):\n",
    "    train_mc = pd.concat([train_mc3,train_mc1])\n",
    "    train_ext = pd.concat([train_ext3,train_ext1])\n",
    "    train_nue = pd.concat([train_nue3,train_nue1])\n",
    "    train_ncpi0 = pd.concat([train_ncpi03,train_ncpi01])\n",
    "    train_ccpi0 = pd.concat([train_ccpi03,train_ccpi01])\n",
    "    test_mc = pd.concat([test_mc3,test_mc1])\n",
    "    test_ext = pd.concat([test_ext3,test_ext1])\n",
    "    test_nue = pd.concat([test_nue3,test_nue1])\n",
    "    test_ncpi0 = pd.concat([test_ncpi03,test_ncpi01])\n",
    "    test_ccpi0 = pd.concat([test_ccpi03,test_ccpi01])\n",
    "    mc = pd.concat([mc3,mc1])\n",
    "    ext = pd.concat([ext3,ext1])\n",
    "    nue = pd.concat([nue3,nue1])\n",
    "    ncpi0 = pd.concat([ncpi03,ncpi01])\n",
    "    ccpi0 = pd.concat([ccpi03,ccpi01])\n",
    "else:\n",
    "    train_mc = train_mc3\n",
    "    train_ext = train_ext3\n",
    "    train_nue = train_nue3\n",
    "    train_ncpi0 = train_ncpi03\n",
    "    train_ccpi0 = train_ccpi03\n",
    "    test_mc = test_mc3\n",
    "    test_ext = test_ext3\n",
    "    test_nue = test_nue3\n",
    "    test_ncpi0 = test_ncpi03\n",
    "    test_ccpi0 = test_ccpi03\n",
    "    mc = mc3\n",
    "    ext = ext3\n",
    "    nue = nue3\n",
    "    ncpi0 = ncpi03\n",
    "    ccpi0 = ccpi03\n",
    "\n",
    "samples = {\n",
    "    \"mc\": (train_mc, test_mc),\n",
    "    \"nue\": (train_nue, test_nue),\n",
    "    \"ext\": (train_ext, test_ext),\n",
    "    \"nc\": (train_ncpi0, test_ncpi0),\n",
    "    \"cc\": (train_ccpi0, test_ccpi0)\n",
    "} \n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "my_booster = nue_booster.NueBooster(samples, TRAINVAR, random_state=1990)\n",
    "\n",
    "print (my_booster.variables)\n",
    "\n",
    "PRESEL = \"reco_e < 1.2 and selected == 1 and n_tracks_contained > 0\"# and (crtveto == 0) and (_closestNuCosmicDist > 20)\"\n",
    "PRESEL += \" and shr_energy_tot_cali > 0.07\"\n",
    "PRESEL += ' and n_showers_contained == 1'\n",
    "PRESEL += ' and hits_ratio > 0.5'\n",
    "PRESEL += ' and tksh_distance < 6.0'\n",
    "PRESEL += ' and shr_tkfit_2cm_dedx_Y < 4.0'\n",
    "PRESEL += ' and tksh_angle > -0.9'\n",
    "PRESEL += ' and trkpid < 0.1'\n",
    "PRESEL += ' and shr_score < 0.30'\n",
    "PRESEL += ' and CosmicIP > 20.'\n",
    "\n",
    "my_booster.set_preselection(PRESEL)\n",
    "\n",
    "gain_imp = {}\n",
    "\n",
    "for label, bkg_query in zip(nue_booster.labels, nue_booster.bkg_queries):\n",
    "    \n",
    "    preds, gain_imp[label] = my_booster.train_booster(ax, bkg_query)\n",
    "    \n",
    "    with open(ls.pickle_path+'booster_%s.pickle' % label, 'wb') as booster_file:\n",
    "        pickle.dump(preds, booster_file)\n",
    "\n",
    "    variables = my_booster.variables.copy()\n",
    "    print ('variables are : ',variables)\n",
    "    variables.remove(\"is_signal\")\n",
    "    variables.remove(\"nu_e\")\n",
    "    variables.remove(\"train_weight\")        \n",
    "        \n",
    "    mc_prediction = preds.predict(\n",
    "        xgb.DMatrix(mc[variables]),\n",
    "        ntree_limit=preds.best_iteration)\n",
    "    nue_prediction = preds.predict(\n",
    "        xgb.DMatrix(nue[variables]),\n",
    "        ntree_limit=preds.best_iteration)\n",
    "    ext_prediction = preds.predict(\n",
    "        xgb.DMatrix(ext[variables]),\n",
    "        ntree_limit=preds.best_iteration)\n",
    "    ncpi0_prediction = preds.predict(\n",
    "        xgb.DMatrix(ncpi0[variables]),\n",
    "        ntree_limit=preds.best_iteration)\n",
    "    ccpi0_prediction = preds.predict(\n",
    "        xgb.DMatrix(ccpi0[variables]),\n",
    "        ntree_limit=preds.best_iteration)\n",
    "\n",
    "    ncpi0[\"%s_score\" % label] = ncpi0_prediction\n",
    "    ccpi0[\"%s_score\" % label] = ccpi0_prediction\n",
    "    mc[\"%s_score\" % label] = mc_prediction\n",
    "    nue[\"%s_score\" % label] = nue_prediction\n",
    "    ext[\"%s_score\" % label] = ext_prediction\n",
    "\n",
    "\n",
    "ax.set_ylim([0, 1.05])\n",
    "ax.set_xlim([0, 1.0])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(ls.plots_path+\"roc_single.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gain_imp['pi0'])\n",
    "print(gain_imp['nonpi0'])\n",
    "\n",
    "gain_imp['pi0']['shr_tkfit_gap10_dedx_ALL'] = gain_imp['pi0']['shr_tkfit_gap10_dedx_V']+gain_imp['pi0']['shr_tkfit_gap10_dedx_U']+gain_imp['pi0']['shr_tkfit_gap10_dedx_Y']\n",
    "gain_imp['pi0']['shr_tkfit_2cm_dedx_ALL'] = gain_imp['pi0']['shr_tkfit_2cm_dedx_V']+gain_imp['pi0']['shr_tkfit_2cm_dedx_U']+gain_imp['pi0']['shr_tkfit_2cm_dedx_Y']\n",
    "gain_imp['nonpi0']['shr_tkfit_gap10_dedx_ALL'] = gain_imp['nonpi0']['shr_tkfit_gap10_dedx_V']+gain_imp['nonpi0']['shr_tkfit_gap10_dedx_U']+gain_imp['nonpi0']['shr_tkfit_gap10_dedx_Y']\n",
    "gain_imp['nonpi0']['shr_tkfit_2cm_dedx_ALL'] = gain_imp['nonpi0']['shr_tkfit_2cm_dedx_V']+gain_imp['nonpi0']['shr_tkfit_2cm_dedx_U']+gain_imp['nonpi0']['shr_tkfit_2cm_dedx_Y']\n",
    "\n",
    "del gain_imp['pi0']['shr_tkfit_gap10_dedx_V']\n",
    "del gain_imp['pi0']['shr_tkfit_gap10_dedx_U']\n",
    "del gain_imp['pi0']['shr_tkfit_gap10_dedx_Y']\n",
    "del gain_imp['pi0']['shr_tkfit_2cm_dedx_V']\n",
    "del gain_imp['pi0']['shr_tkfit_2cm_dedx_U']\n",
    "del gain_imp['pi0']['shr_tkfit_2cm_dedx_Y']\n",
    "del gain_imp['nonpi0']['shr_tkfit_gap10_dedx_V']\n",
    "del gain_imp['nonpi0']['shr_tkfit_gap10_dedx_U']\n",
    "del gain_imp['nonpi0']['shr_tkfit_gap10_dedx_Y']\n",
    "del gain_imp['nonpi0']['shr_tkfit_2cm_dedx_V']\n",
    "del gain_imp['nonpi0']['shr_tkfit_2cm_dedx_U']\n",
    "del gain_imp['nonpi0']['shr_tkfit_2cm_dedx_Y']\n",
    "\n",
    "labels = []\n",
    "pi0_imp = []\n",
    "nonpi0_imp = []\n",
    "\n",
    "for i in sorted (gain_imp['pi0'].keys()) :  \n",
    "    labels.append(i)\n",
    "    pi0_imp.append(gain_imp['pi0'][i])\n",
    "    nonpi0_imp.append(gain_imp['nonpi0'][i])\n",
    "    \n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, pi0_imp, width, label='pi0')\n",
    "rects2 = ax.bar(x + width/2, nonpi0_imp, width, label='nonpi0')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('total gain')\n",
    "ax.set_title('BDT Variable Importance')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation = 90)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pi0_rnk = {}\n",
    "rnk = len(labels)\n",
    "for w in sorted(gain_imp['pi0'], key=gain_imp['pi0'].get, reverse=True):\n",
    "    d_pi0_rnk[w] = rnk\n",
    "    rnk = rnk-1\n",
    "print(d_pi0_rnk)\n",
    "\n",
    "d_nonpi0_rnk = {}\n",
    "rnk = len(labels)\n",
    "for w in sorted(gain_imp['nonpi0'], key=gain_imp['nonpi0'].get, reverse=True):\n",
    "    d_nonpi0_rnk[w] = rnk\n",
    "    rnk = rnk-1\n",
    "print(d_nonpi0_rnk)\n",
    "\n",
    "pi0_rnk = []\n",
    "nonpi0_rnk = []\n",
    "\n",
    "for i in labels:  \n",
    "    pi0_rnk.append(d_pi0_rnk[i])\n",
    "    nonpi0_rnk.append(d_nonpi0_rnk[i])\n",
    "    \n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, pi0_rnk, width, label='pi0')\n",
    "rects2 = ax.bar(x + width/2, nonpi0_rnk, width, label='nonpi0')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Rank (based on total gain)')\n",
    "ax.set_title('BDT Variable Importance')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation = 90)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
