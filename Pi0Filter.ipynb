{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import localSettings as ls\n",
    "print(ls.main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%m%d%Y\")\n",
    "print(\"date and time:\",date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1560556807118,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "6qsD0G-yYJ9K",
    "outputId": "5d52a3ec-50be-44fc-da44-3c0593e98bc6"
   },
   "outputs": [],
   "source": [
    "main_path = ls.main_path\n",
    "sys.path.append(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHRCALIBFACTOR = 1.03 # scale data by this amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Run3?\n",
    "ISRUN3 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGqTJ5JgaDsx"
   },
   "outputs": [],
   "source": [
    "import plotter\n",
    "import importlib\n",
    "importlib.reload(plotter)\n",
    "import uproot\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import nue_booster \n",
    "importlib.reload(nue_booster)\n",
    "import awkward\n",
    "\n",
    "params = {\n",
    "    'axes.labelsize': 'x-large',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'ytick.labelsize': 'x-large'\n",
    "}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwoCIaigYJ9N"
   },
   "outputs": [],
   "source": [
    "fold = \"nuselection\"\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "\n",
    "PI0DIR = ''\n",
    "\n",
    "BNB = \"\"\n",
    "EXT = \"\"\n",
    "NU  = \"\"\n",
    "NUE = \"\"\n",
    "DRT = \"\"\n",
    "PI0 = \"\"\n",
    "CCPI0 = \"\"\n",
    "\n",
    "DATAFLDR = \"pi0/\"\n",
    "MCFLDR = \"\"\n",
    "\n",
    "if ISRUN3:\n",
    "    BNB = 'data_bnb_mcc9.1_v08_00_00_25_reco2_G1_pi0_reco2'\n",
    "    EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_RUN3_pi0_reco2'\n",
    "    NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run3_reco2_G_reco2'\n",
    "    NUE = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'\n",
    "    DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'\n",
    "    NCPI0 = 'prodgenie_nc_pi0_uboone_overlay_mcc9.1_v08_00_00_26_run3_G_reco2'\n",
    "    CCPI0 = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run3_G_reco2'\n",
    "    CCNOPI = 'prodgenie_CCmuNoPi_overlay_mcc9_v08_00_00_33_run3_reco2_reco2'\n",
    "    NCCPI = 'prodgenie_NCcPiNoPi0_overlay_mcc9_v08_00_00_33_New_run3_reco2_reco2'\n",
    "    NCNOPI = 'prodgenie_ncnopi_overlay_mcc9_v08_00_00_33_new_run3_reco2_reco2'\n",
    "    MCFLDR = \"run3/\"\n",
    "    \n",
    "else:\n",
    "    BNB = 'data_bnb_mcc9.1_v08_00_00_25_reco2_C1_pi0_reco2'\n",
    "    #BNB = 'data_bnb_mcc9.1_v08_00_00_25_reco2_C1_beam_good_reco2_5e19' # 5E19\n",
    "    EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_RUN1_pi0_reco2'\n",
    "    #EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C1_all_reco2' # 5E19\n",
    "    NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run1_reco2_reco2'\n",
    "    NUE = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'\n",
    "    DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'\n",
    "    NCPI0 = 'prodgenie_nc_pi0_uboone_overlay-v08_00_00_26_run1_reco2_reco2'\n",
    "    CCPI0 = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run1_reco2'\n",
    "    CCNOPI = 'prodgenie_CCmuNoPi_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "    NCCPI = 'prodgenie_NCcPiNoPi0_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "    NCNOPI = 'prodgenie_ncnopi_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "    MCFLDR = \"run1/\"\n",
    "    \n",
    "mc = uproot.open(ls.main_path+MCFLDR+NU+\".root\")[fold][tree]\n",
    "ncpi0 = uproot.open(ls.main_path+MCFLDR+NCPI0+\".root\")[fold][tree]\n",
    "ccpi0 = uproot.open(ls.main_path+MCFLDR+CCPI0+\".root\")[fold][tree]\n",
    "ccnopi = uproot.open(ls.main_path+MCFLDR+CCNOPI+\".root\")[fold][tree]\n",
    "nccpi = uproot.open(ls.main_path+MCFLDR+NCCPI+\".root\")[fold][tree]\n",
    "ncnopi = uproot.open(ls.main_path+MCFLDR+NCNOPI+\".root\")[fold][tree]\n",
    "nue = uproot.open(ls.main_path+MCFLDR+NUE+\".root\")[fold][tree]\n",
    "data = uproot.open(ls.main_path+DATAFLDR+BNB+\".root\")[fold][tree]\n",
    "ext = uproot.open(ls.main_path+DATAFLDR+EXT+\".root\")[fold][tree]\n",
    "dirt = uproot.open(ls.main_path+MCFLDR+DRT+\".root\")[fold][tree]\n",
    "lee = uproot.open(ls.main_path+MCFLDR+NUE+\".root\")[fold][tree]\n",
    "\n",
    "uproot_v = [lee,mc,ncpi0,ccpi0,ccnopi,nccpi,ncnopi,nue,ext,data,dirt]\n",
    "\n",
    "variables = [\n",
    "    \"shr_bkt_pdg\", \"selected\", \"nu_pdg\",\n",
    "    \"slpdg\", \"trk_score_v\", \"backtracked_pdg\", # modified from shr_score_v\n",
    "    \"category\",\n",
    "    \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "    \"nu_e\",\"trk_bkt_pdg\",\"ccnc\",\n",
    "    \"mc_pdg\", \"npi0\",\n",
    "    \"run\",\"sub\",\"evt\",\n",
    "    \"filter_pi0\",\"pi0_e\",\n",
    "    \"trk_id\",\"trk_llr_pid_score_v\",\n",
    "    \"interaction\",\n",
    "    \"topological_score\",\"trk_len\",\n",
    "    \"evnunhits\", \"nslice\", \"selected\",\n",
    "    \"reco_nu_vtx_x\", \"reco_nu_vtx_y\", \"reco_nu_vtx_z\",\n",
    "    \"slnunhits\",\"slnhits\",\n",
    "    # pi0 variables\n",
    "    \"pi0_radlen1\",\"pi0_radlen2\",\"pi0_dot1\",\"pi0_dot2\",\"pi0_energy1_Y\",\"pi0_energy2_Y\",\n",
    "    \"pi0_dedx1_fit_Y\",\"pi0_dedx2_fit_Y\",\"pi0_shrscore1\",\"pi0_shrscore2\",\"pi0_gammadot\",\n",
    "    \"pi0_mass_Y\",\"pi0_mass_V\",\"pi0_mass_U\",\n",
    "    \"tksh_distance\",\"shr_tkfit_gap10_dedx_Y\",\"shr_tkfit_gap10_dedx_V\",\"shr_tkfit_gap10_dedx_U\",\n",
    "    \"shr_tkfit_2cm_dedx_Y\",\"shr_tkfit_2cm_dedx_V\",\"shr_tkfit_2cm_dedx_U\",\n",
    "    \"tksh_angle\",\"shrmoliereavg\",\"n_showers_contained\",\n",
    "    \"shr_score\",\"hits_ratio\",\"CosmicIP\",\"secondshower_Y_nhit\",\"secondshower_Y_dot\",\n",
    "    \"secondshower_Y_vtxdist\",\"shr_energy_tot_cali\",\n",
    "    \"shrsubclusters0\",\"shrsubclusters1\",\"shrsubclusters2\",\n",
    "    \"n_tracks_contained\",\"secondshower_Y_dir\",\"shrclusdir2\",\n",
    "    \"shr_tkfit_npoints\",\"shr_tkfit_npointsvalid\"\n",
    "    ]\n",
    "\n",
    "WEIGHTS = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\"]#, \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "WEIGHTSLEE = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\", \"leeweight\"]#, \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "MCFVARS = [\"mcf_nu_e\",\"mcf_lep_e\",\"mcf_actvol\",\"mcf_nmm\",\"mcf_nmp\",\"mcf_nem\",\"mcf_nep\",\"mcf_np0\",\"mcf_npp\",\n",
    "           \"mcf_npm\",\"mcf_mcshr_elec_etot\",\"mcf_pass_ccpi0\",\"mcf_pass_ncpi0\",\n",
    "           \"mcf_pass_ccnopi\",\"mcf_pass_ncnopi\",\"mcf_pass_cccpi\",\"mcf_pass_nccpi\"]\n",
    "SYSTEMATICS =  ['weightsFlux','weightsGenie']\n",
    "\n",
    "nue = nue.pandas.df(variables + WEIGHTS + SYSTEMATICS, flatten=False)\n",
    "mc = mc.pandas.df(variables + WEIGHTS + MCFVARS  + SYSTEMATICS, flatten=False)\n",
    "ncpi0 = ncpi0.pandas.df(variables + WEIGHTS  + SYSTEMATICS, flatten=False)\n",
    "ccpi0 = ccpi0.pandas.df(variables + WEIGHTS  + SYSTEMATICS, flatten=False)\n",
    "ccnopi = ccnopi.pandas.df(variables + WEIGHTS + SYSTEMATICS, flatten=False)\n",
    "nccpi = nccpi.pandas.df(variables + WEIGHTS + SYSTEMATICS, flatten=False)\n",
    "ncnopi = ncnopi.pandas.df(variables + WEIGHTS + SYSTEMATICS, flatten=False)\n",
    "data = data.pandas.df(variables, flatten=False)\n",
    "ext = ext.pandas.df(variables, flatten=False)\n",
    "dirt = dirt.pandas.df(variables + WEIGHTS + SYSTEMATICS, flatten=False)\n",
    "lee = lee.pandas.df(variables + WEIGHTSLEE + SYSTEMATICS, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,nccpi,ncnopi,nue,ext,data,dirt]\n",
    "\n",
    "# and a way to filter out data\n",
    "for i,df in enumerate(df_v):\n",
    "    df[\"bnbdata\"] = np.zeros_like(df[\"topological_score\"])\n",
    "    df[\"extdata\"] = np.zeros_like(df[\"topological_score\"])\n",
    "data[\"bnbdata\"] = np.ones_like(data[\"topological_score\"])\n",
    "ext[\"extdata\"]  = np.ones_like(ext[\"topological_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,nccpi,ncnopi,nue,dirt]\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    \n",
    "    df.loc[ df['weightTune'] <= 0, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] == np.inf, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] > 100, 'weightTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightTune']) == True, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] <= 0, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] == np.inf, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] > 100, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightSplineTimesTune']) == True, 'weightSplineTimesTune' ] = 1.\n",
    "    # scale pi0s\n",
    "    df.loc[ df['npi0'] > 0, 'weightSplineTimesTune' ] = df['weightSpline'] * df['weightTune'] * 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nc['weightSplineTimesTune'] =  nc['weightSplineTimesTune']*0.10\n",
    "#ccpi0['weightSplineTimesTune'] =  ccpi0['weightSplineTimesTune']*0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 243. * (23.6/1e6) / 0.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,nccpi,ncnopi,nue,ext,data,dirt]\n",
    "\n",
    "# energy scaling\n",
    "for i,df in enumerate(df_v):\n",
    "    df[\"pi0_mass_Y_calib\"] = df['pi0_mass_Y']\n",
    "    df[\"pi0_dedx1_fit_Y_calib\"] = df['pi0_dedx1_fit_Y'] #* F\n",
    "    df[\"pi0_dedx2_fit_Y_calib\"] = df['pi0_dedx2_fit_Y'] #* F\n",
    "    df['pi0_reco_mom'] = np.sqrt(((df['pi0_energy1_Y'] + df['pi0_energy2_Y'])/0.8)**2-135*135)\n",
    "    \n",
    "data['pi0_mass_Y_calib'] = data['pi0_mass_Y_calib'] * 1.03\n",
    "ext['pi0_mass_Y_calib'] = ext['pi0_mass_Y_calib'] * 1.03\n",
    "\n",
    "data['pi0_dedx1_fit_Y_calib'] = data['pi0_dedx1_fit_Y_calib'] * 1.03 \n",
    "ext['pi0_dedx1_fit_Y_calib'] = ext['pi0_dedx1_fit_Y_calib'] * 1.03 \n",
    "\n",
    "data['pi0_dedx2_fit_Y_calib'] = data['pi0_dedx2_fit_Y_calib'] * 1.03\n",
    "ext['pi0_dedx2_fit_Y_calib'] = ext['pi0_dedx2_fit_Y_calib'] * 1.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,nccpi,ncnopi,nue,ext,data,dirt]\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "    df['trkfit'] = df['shr_tkfit_npointsvalid'] / df['shr_tkfit_npoints']\n",
    "    df['anglediff_Y'] = np.abs(df['secondshower_Y_dir']-df['shrclusdir2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid double-counting of events out of FV in the NC/CC pi0 samples\n",
    "# not needed anymore since we improved matching with filtered samples\n",
    "#ncpi0 = ncpi0.query('category != 5')\n",
    "#ccpi0 = ccpi0.query('category != 5')\n",
    "#ccnopi = ccnopi.query('category != 5')\n",
    "#nccpi = nccpi.query('category != 5')\n",
    "#ncnopi = ncnopi.query('category != 5')\n",
    "\n",
    "# avoid recycling unbiased ext events (i.e. selecting a slice with little nu content from these samples)\n",
    "ccnopi = ccnopi.query('(nslice==0 | (slnunhits/slnhits)>0.2)')\n",
    "nccpi = nccpi.query('(nslice==0 | (slnunhits/slnhits)>0.2)')\n",
    "ncnopi = ncnopi.query('(nslice==0 | (slnunhits/slnhits)>0.2)')\n",
    "\n",
    "# add back the cosmic category, for background only\n",
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,nccpi,ncnopi,nue,ext,data,dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    df.loc[(df['category']!=1)&(df['category']!=10)&(df['category']!=11)&(df['category']!=111)&(df['slnunhits']/df['slnhits']<0.2), 'category'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lee[\"is_signal\"] = lee[\"category\"] == 11\n",
    "data[\"is_signal\"] = data[\"category\"] == 11\n",
    "nue[\"is_signal\"] = nue[\"category\"] == 11\n",
    "mc[\"is_signal\"] = mc[\"category\"] == 11\n",
    "dirt[\"is_signal\"] = dirt[\"category\"] == 11\n",
    "ext[\"is_signal\"] = ext[\"category\"] == 11\n",
    "ncpi0[\"is_signal\"] = ncpi0[\"category\"] == 11\n",
    "ccpi0[\"is_signal\"] = ccpi0[\"category\"] == 11\n",
    "ccnopi[\"is_signal\"] = ccnopi[\"category\"] == 11\n",
    "nccpi[\"is_signal\"] = nccpi[\"category\"] == 11\n",
    "ncnopi[\"is_signal\"] = ncnopi[\"category\"] == 11\n",
    "\n",
    "lee.loc[lee['category'] == 1, 'category'] = 111\n",
    "lee.loc[lee['category'] == 10, 'category'] = 111\n",
    "lee.loc[lee['category'] == 11, 'category'] = 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotter\n",
    "import importlib\n",
    "importlib.reload(plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pamv0W8YJ9R"
   },
   "outputs": [],
   "source": [
    "samples = {\n",
    "    \"mc\": mc,\n",
    "    \"nue\": nue,\n",
    "    \"data\": data,\n",
    "    \"ext\": ext,\n",
    "    \"dirt\": dirt,\n",
    "    \"ncpi0\": ncpi0,\n",
    "    \"ccpi0\": ccpi0,\n",
    "    \"ccnopi\": ccnopi,\n",
    "    \"nccpi\": nccpi,\n",
    "    \"ncnopi\": ncnopi,\n",
    "    \"lee\": lee\n",
    "}\n",
    "\n",
    "scaling = 1\n",
    "#scaling = 132.0/0.486\n",
    "#scaling = 132.0/3.9\n",
    "\n",
    "SPLIT = 1.0\n",
    "\n",
    "#''' 1115\n",
    "if ISRUN3:\n",
    "    weights = {\n",
    "        \"mc\": 9.75e-2 * SPLIT * scaling,\n",
    "        \"nue\": 2.25e-3 * SPLIT * scaling,\n",
    "        \"ext\": 3.51e-1 * SPLIT * scaling,\n",
    "        \"dirt\": 4.02e-1 * scaling,\n",
    "        \"lee\": 2.25e-3 * SPLIT * scaling,\n",
    "        \"ncpi0\": 5.68e-2 * SPLIT * scaling,\n",
    "        \"ccpi0\": 2.07e-2 * SPLIT * scaling,\n",
    "        \"ccnopi\": 1.19e-01 * SPLIT * scaling,\n",
    "        \"nccpi\": 1.81e-02 * SPLIT * scaling,\n",
    "        \"ncnopi\": 4.23e-02 * SPLIT * scaling,\n",
    "    }\n",
    "    pot = 1.27e20*scaling\n",
    "else:\n",
    "    weights = {\n",
    "        \"mc\": 3.79e-2 * SPLIT * scaling,\n",
    "        \"nue\": 6.36e-4 * SPLIT * scaling,\n",
    "        \"ext\": 3.13e-1 * SPLIT * scaling,\n",
    "        \"dirt\": 1.24e-1 * scaling,\n",
    "        \"lee\": 6.36e-4 * SPLIT * scaling,\n",
    "        \"ncpi0\": 1.33e-2 * SPLIT * scaling,\n",
    "        \"ccpi0\": 1.06e-2 * SPLIT * scaling,\n",
    "        \"ccnopi\": 1.35e-02 * SPLIT * scaling,\n",
    "        \"nccpi\": 4.14e-03 * SPLIT * scaling,\n",
    "        \"ncnopi\": 1.08e-02 * SPLIT * scaling,\n",
    "    }\n",
    "    pot = 3.34e19*scaling\n",
    "#'''\n",
    "\n",
    "\n",
    "\n",
    "my_plotter = plotter.Plotter(samples, weights, pot=pot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "VAR_V = ['pi0_shrscore1','pi0_shrscore2','pi0_dot1','pi0_dot2',\\\n",
    "        'pi0_radlen1','pi0_radlen2','pi0_gammadot',\\\n",
    "        'pi0_energy1_Y','pi0_energy2_Y',\\\n",
    "        'pi0_dedx1_fit_Y','pi0_dedx2_fit_Y']\n",
    "\n",
    "LABEL_V = ['leading shower score','sub-leading shower score','leading shower vtx alignment [dot-product]',\\\n",
    "          'sub-leading shower vtx alignment [dot-product]','leading shower conversion distance [cm]',\\\n",
    "          'sub-leading shower conversion distance [cm]','di-photon opening angle [rad]','leading shower energy',\\\n",
    "          'sub-leading shower energy',\\\n",
    "          'leading dEdx [MeV/cm]','sub-leading dE/dx [MeV/cm]']\n",
    "\n",
    "RANGE_V = [(0,0.8),(0,0.8),(0.8,1),(0.8,1),(3,100),(3,100),(0,0.94),(50,500),(20,300),(0,10),(0,10)]\n",
    "\n",
    "SCORECUT = 0.8 # max track score\n",
    "DVTX = 3. # distance from vertex of each shower\n",
    "VTXDOT = 0.8 # dot product between each shower's direction and the vtx -> shr start vector\n",
    "EMIN1 = 50. # leading photon min energy\n",
    "EMIN2 = 20. # subleading photon min energy\n",
    "GAMMADOT = 0.94 # max dot product between showres\n",
    "\n",
    "SELQUERY = 'nslice == 1'\n",
    "SELQUERY += ' & pi0_shrscore1 < %f & pi0_shrscore2 < %f'%(SCORECUT,SCORECUT)\n",
    "SELQUERY += '& pi0_dot1  > %f & pi0_dot2 > %f '%(VTXDOT,VTXDOT)\n",
    "SELQUERY += ' & pi0_radlen1 > %f & pi0_radlen2 > %f & pi0_gammadot < %f '%(DVTX,DVTX,GAMMADOT)\n",
    "SELQUERY += ' & pi0_energy1_Y > %f & pi0_energy2_Y > %f'%(EMIN1,EMIN2)\n",
    "\n",
    "for N in range(len(VAR_V)):\n",
    "\n",
    "    VARIABLE, BINS, RANGE, XTIT = VAR_V[N],30,RANGE_V[N],LABEL_V[N]\n",
    "\n",
    "    fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "        VARIABLE,   \n",
    "        query=SELQUERY,\n",
    "        kind=\"event_category\",\n",
    "        #kind=\"interaction\",\n",
    "        #kind=\"sample\",\n",
    "        #kind='particle_pdg',\n",
    "        draw_sys=False,\n",
    "        title=XTIT,\n",
    "        bins=BINS,\n",
    "        range=RANGE,\n",
    "    )\n",
    "\n",
    "    #ax1.set_yscale('log')\n",
    "    ax1.set_ylim(0,ax1.get_ylim()[1]*1.45)\n",
    "    fig.savefig(ls.plots_path+\"pi0/\"+VARIABLE+\"_\"+date_time+\"_inputs_RUN3.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1eNp box-cuts\n",
    "# nue pre-selection\n",
    "QUERY = 'nslice == 1'\n",
    "QUERY += ' and selected == 1'\n",
    "QUERY += ' and n_tracks_contained > 0'\n",
    "QUERY += ' and shr_energy_tot_cali > 0.07'\n",
    "QUERY += ' and n_tracks_contained > 0'\n",
    "# Loose box cuts\n",
    "#QUERY += ' and n_showers_contained == 1'\n",
    "#QUERY += ' and hits_ratio > 0.5'\n",
    "#QUERY += ' and tksh_distance < 6.0'\n",
    "#QUERY += ' and shr_tkfit_2cm_dedx_Y < 4.0'\n",
    "#QUERY += ' and tksh_angle > -0.9'\n",
    "#QUERY += ' and trkpid < 0.1'\n",
    "#QUERY += ' and shr_score < 0.30'\n",
    "#QUERY += ' and CosmicIP > 20.'\n",
    "# Box cuts\n",
    "#QUERY += ' and tksh_distance < 3.5'\n",
    "#QUERY += ' and (shr_tkfit_gap10_dedx_Y > 0 and shr_tkfit_gap10_dedx_Y < 4.5 and shr_tkfit_gap10_dedx_U < 4.5 and shr_tkfit_gap10_dedx_V < 4.5)'\n",
    "#QUERY += ' and (shr_tkfit_2cm_dedx_Y > 0 and shr_tkfit_2cm_dedx_Y < 4.0 and shr_tkfit_2cm_dedx_U < 4.0 and shr_tkfit_2cm_dedx_V < 4.0)'\n",
    "#QUERY += ' and tksh_angle > -0.9 and tksh_angle < 0.7'\n",
    "#QUERY += ' and shrmoliereavg > 2 and shrmoliereavg < 9'\n",
    "#QUERY += ' and trkpid < -0.02'\n",
    "#QUERY += ' and n_showers_contained == 1'\n",
    "#QUERY += ' and shr_score < 0.275'\n",
    "#QUERY += ' and hits_ratio > 0.60'\n",
    "#QUERY += ' and CosmicIP > 20.'\n",
    "#QUERY += ' and (secondshower_Y_nhit<=8 or secondshower_Y_dot<=0.8 or anglediff_Y<=40 or secondshower_Y_vtxdist>=100)'\n",
    "#QUERY += ' and (trkfit < 0.45 or subcluster > 6)'\n",
    "\n",
    "QUERY += ' and (filter_pi0 == 1 or bnbdata==1 or extdata==1)'\n",
    "\n",
    "\n",
    "# in case you do not want to look at the data\n",
    "#QUERY += ' and bnbdata==0 '# and category != 111'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORECUT = 0.75 # 0.75 #75 # max track score\n",
    "DVTX = 3.0 # 3. # distance from vertex of each shower\n",
    "VTXDOT = 0.8 # dot product between each shower's direction and the vtx -> shr start vector\n",
    "EMIN1 =  50. # leading photon min energy\n",
    "EMIN2 =  20. #20. # 20. # subleading photon min energy\n",
    "GAMMADOT = 0.94 # max dot product between showres\n",
    "#DEDXCUT = 0.5 # MeV/cm cut on leading shower only\n",
    "\n",
    "#SCORECUT = 0.3 # 0.75 #75 # max track score\n",
    "#DVTX = 3.0 # 3. # distance from vertex of each shower\n",
    "#TXDOT = 0.8 # dot product between each shower's direction and the vtx -> shr start vector\n",
    "#EMIN1 =  70. # leading photon min energy\n",
    "#EMIN2 =  20. #20. # 20. # subleading photon min energy\n",
    "#GAMMADOT = 0.94 # max dot product between showres\n",
    "#DEDXCUT = 0.5 # MeV/cm cut on leading shower only\n",
    "\n",
    "#SELQUERY = 'nslice == 1'\n",
    "#SELQUERY += ' & pi0_shrscore1 < %f & pi0_shrscore2 < %f'%(SCORECUT,SCORECUT)\n",
    "#SELQUERY += '& pi0_dot1  > %f & pi0_dot2 > %f '%(VTXDOT,VTXDOT)\n",
    "#SELQUERY += ' & pi0_radlen1 > %f & pi0_radlen2 > %f & pi0_gammadot < %f '%(DVTX,DVTX,GAMMADOT)\n",
    "#SELQUERY += ' & pi0_energy1_Y > %f & pi0_energy2_Y > %f'%(EMIN1,EMIN2)\n",
    "#SELQUERY += ' and (filter_pi0 == 1 or bnbdata==1 or extdata==1)'\n",
    "SELQUERY += ' and selected == 1'\n",
    "#SELQUERY += ' & crtveto==0'\n",
    "#SELQUERY += ' and dedx1 > %f'%DEDXCUT\n",
    "#SELQUERY += ' and pi0_energy1_Y > 200.'\n",
    "\n",
    "print (SELQUERY)\n",
    "\n",
    "QUERY = SELQUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2342,
     "status": "ok",
     "timestamp": 1560557343774,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "b93hN-pGYJ9T",
    "outputId": "17e7c7ed-3f12-4b03-805c-6698f1617878",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_2cm_dedx_V',30,(0.,10.),r\"dE/dx trkfit 2cm [MeV/cm]\"\n",
    "\n",
    "fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "    VARIABLE,   \n",
    "    query=QUERY + \" and category != 111\",\n",
    "    kind=\"event_category\",\n",
    "    #kind=\"interaction\",\n",
    "    #kind=\"sample\",\n",
    "    #kind='particle_pdg',\n",
    "    draw_sys=False,\n",
    "    stacksort=True,\n",
    "    title=XTIT,\n",
    "    #bins=asymm_bins,\n",
    "    bins=BINS,\n",
    "    range=RANGE,\n",
    ")\n",
    "\n",
    "#print(\"Profile likelihood: %.2f sigma @ 1.32e21 POT\" % my_plotter.significance_likelihood)\n",
    "#print(\"s/sqrt(b): %.2f sigma @ 1.32e21 POT\" % my_plotter.significance)\n",
    "\n",
    "ax1.set_ylim(1,ax1.get_ylim()[1]*1.45)\n",
    "#ax1.set_ylim(0,200)\n",
    "#ax1.set_yscale(\"log\")\n",
    "#ax1.set_ylim(0,0.25)\n",
    "#ax2.set_ylim(0.5,1.5)\n",
    "fig.savefig(ls.main_path+\"pi0/plots/\"+VARIABLE+\"_\"+date_time+\"_scaled_RUN3.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datasel = data.query(QUERY)\n",
    "print ((datasel['run'].values)[:10])\n",
    "print ((datasel['sub'].values)[:10])\n",
    "print ((datasel['evt'].values)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eff(df,var,query,acceptance,bin_edges,absval=False):\n",
    "    #print acceptance\n",
    "    bin_centers = 0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "    bins = []\n",
    "    bin_eff = []\n",
    "    bin_err = []\n",
    "    for i in range(len(bin_centers)):\n",
    "        binmin = bin_edges[i]\n",
    "        binmax = bin_edges[i+1]\n",
    "        bincut = '%s > %f and %s < %f'%(var,binmin,var,binmax)\n",
    "        if (absval == True):\n",
    "            bincut = '(%s > %f and %s < %f) or (%s > -%f and %s < -%f)'%(var,binmin,var,binmax,var,binmax,var,binmin)\n",
    "        if (acceptance != ''): bincut += ' and %s'%acceptance\n",
    "        #print bincut\n",
    "        df_tmp =  df.query(bincut) # cut on bin range for desired var.\n",
    "        df_sub = df_tmp.query(query) # apply constrain \n",
    "        if (df_tmp.shape[0] == 0): continue\n",
    "        eff = df_sub.shape[0] / float( df_tmp.shape[0] )\n",
    "        err = np.sqrt( eff*(1-eff)/df_tmp.shape[0] )\n",
    "        bin_eff.append( eff )\n",
    "        bin_err.append( err )\n",
    "        bins.append(bin_centers[i])\n",
    "        #print 'eff = %.02f @ bin = %.02f'%(eff,bin_centers[i])\n",
    "    return np.array(bins),np.array(bin_eff),np.array(bin_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "B = np.linspace(0.0,0.8,25)\n",
    "\n",
    "ACCEPTANCE = 'pi0_e > 0 and ccnc==0'\n",
    "#QUERY = SELQUERY\n",
    "VAR = 'pi0_e' #'_pi0_e'\n",
    "\n",
    "centers,vals,errs = Eff(ccpi0,VAR,QUERY,ACCEPTANCE,B)\n",
    "plt.errorbar(centers,vals,yerr=errs,fmt='o-',color='b',label=r'$\\pi^0$ selection [CC]')\n",
    "\n",
    "ACCEPTANCE = 'pi0_e > 0 and ccnc==1'\n",
    "#QUERY = SELQUERY\n",
    "VAR = 'pi0_e' #'_pi0_e'\n",
    "\n",
    "centers,vals,errs = Eff(nc,VAR,QUERY,ACCEPTANCE,B)\n",
    "plt.errorbar(centers,vals,yerr=errs,fmt='o-',color='r',label=r'$\\pi^0$ selection [NC]')\n",
    "\n",
    "plt.xlabel(r'$\\pi^0$ Energy [GeV]',fontsize=16)\n",
    "plt.ylabel(r'Efficiency',fontsize=16)\n",
    "plt.grid()\n",
    "plt.ylim([0,0.7])\n",
    "plt.legend(loc=9,fontsize=16,framealpha=1.0)\n",
    "#plt.yscale('log')\n",
    "#plt.title(r'v08_00_00_26 Run1 Samples')\n",
    "#plt.legend(loc=7,fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Plotter.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
