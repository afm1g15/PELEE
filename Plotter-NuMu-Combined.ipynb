{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import management\n",
    "import autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2  # Autoreload all modules\n",
    "import importlib\n",
    "\n",
    "#standard imports\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "#custom modules\n",
    "import localSettings as ls\n",
    "import plotter\n",
    "import NUMUhelper as moreFunctions\n",
    "#import xgboost as xgb\n",
    "#import nue_booster \n",
    "\n",
    "#scientific imports\n",
    "import uproot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.backends.backend_pdf\n",
    "import numpy as np\n",
    "#import awkward\n",
    "import math\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#put these throughout the code to reload if needed\n",
    "importlib.reload(ls)\n",
    "importlib.reload(plotter)\n",
    "importlib.reload(moreFunctions)\n",
    "\n",
    "main_path = ls.main_path\n",
    "sys.path.append(main_path)\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%m%d%Y\")\n",
    "print(\"date and time:\",date_time)\n",
    "params = {\n",
    "    'axes.labelsize': 'x-large',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'ytick.labelsize': 'x-large'\n",
    "}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main 'control center'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What're we looking at today\n",
    "LOADDETSYS = True #load Genie + Flux systematic errors\n",
    "USECRT = False #load/apply CRT variables/cuts\n",
    "NPROTON_CAT = True #break 1mu into Xp final states in 'category' variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#header###########################\n",
    "importlib.reload(ls)\n",
    "importlib.reload(moreFunctions)\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "#################################\n",
    "# locate files\n",
    "# /uboone/data/users/davidc/searchingfornues/v08_00_00_33/cc0pinp/0304/\n",
    "# Loading in all available info\n",
    "\n",
    "numupresel_path = \"E:\\\\HEPPA\\\\Data\\\\PeLEE\\\\0304_numupresel\\\\\"\n",
    "BNB = {\n",
    "    1: [ls.ntuple_path+\"neutrinoselection_filt_C1\"],\n",
    "    2: [ls.ntuple_path+\"neutrinoselection_filt_D2\",ls.ntuple_path+\"neutrinoselection_filt_E1\"],\n",
    "    3: [ls.ntuple_path+\"neutrinoselection_filt_G1\"],\n",
    "}\n",
    "BNB['combined'] = BNB[1] + BNB[2] + BNB[3]\n",
    "\n",
    "ext_samples = {\n",
    "    1: [\"C1\",\"C2\"],\n",
    "    2: [\"D1\",\"D2\",\"E1\",\"E2\"],\n",
    "    3: [\"G1\",\"G2\"]\n",
    "}\n",
    "ext_prefix = \"data_extbnb_mcc9.1_v08_00_00_25_reco2_{}_all_reco2_numupresel\"\n",
    "EXT = {\n",
    "    1: [numupresel_path+\"Run1\\\\{}\".format(ext_prefix).format(x) for x in ext_samples[1]],\n",
    "    2: [numupresel_path+\"Run2\\\\{}\".format(ext_prefix).format(x) for x in ext_samples[2]],\n",
    "    3: [numupresel_path+\"Run3\\\\{}\".format(ext_prefix).format(x) for x in ext_samples[3]],\n",
    "    'combined': [numupresel_path + 'data_extbnb_mcc9.1_v08_00_00_25_rec2_C1_C2_D1_D2_E1_E2_G1_G2_numupresel']\n",
    "}\n",
    "#EXT['combined1'] = EXT[1] + EXT[2] + EXT[3]\n",
    "\n",
    "DIRT = {\n",
    "    1: [numupresel_path+\"Run1\\\\prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2_numupresel\"],\n",
    "    3: [numupresel_path+\"Run3\\\\prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2_numupresel\"]\n",
    "}\n",
    "DIRT[2] = DIRT[1] + DIRT[3]\n",
    "DIRT['combined'] = DIRT[1] + DIRT[3]\n",
    "\n",
    "MC = {\n",
    "    1: [numupresel_path+\"Run1\\\\prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run1_reco2_reco2_numupresel\"],\n",
    "    2: [numupresel_path+\"Run2\\\\prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run2_reco2_D1D2_reco2_numupresel\"],\n",
    "    3: [numupresel_path+\"Run3\\\\prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run3_reco2_G_reco2_numupresel\"]\n",
    "}\n",
    "MC['combined'] = MC[1] + MC[2] + MC[3]\n",
    "\n",
    "#################################\n",
    "#make uproot files\n",
    "data, ext, dirt, mc = {},{},{},{}\n",
    "for run in BNB: BNB[run] = [uproot.open(filepath+\".root\")[ls.fold][tree] for filepath in BNB[run]]\n",
    "for run in EXT: EXT[run] = [uproot.open(filepath+\".root\")[ls.fold][tree] for filepath in EXT[run]]\n",
    "for run in DIRT: DIRT[run] = [uproot.open(filepath+\".root\")[ls.fold][tree] for filepath in DIRT[run]]\n",
    "for run in MC: MC[run] = [uproot.open(filepath+\".root\")[ls.fold][tree] for filepath in MC[run]]\n",
    "\n",
    "#################################\n",
    "# declare necessary variables\n",
    "variables = [\n",
    "    \"nslice\",\n",
    "    \"slpdg\", \"trk_score_v\",\"slclustfrac\",\n",
    "    \"pfnhits\",\"pfnunhits\",'slnunhits','slnhits',#\"contained_fraction\",\n",
    "    \"topological_score\",\n",
    "    \"run\", \"sub\", \"evt\",\n",
    "    'NeutrinoEnergy2',\n",
    "    #\"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "    #\"trk_sce_start_x_v\",\"trk_sce_start_y_v\",\"trk_sce_start_z_v\",\n",
    "    #\"trk_sce_end_x_v\",\"trk_sce_end_y_v\",\"trk_sce_end_z_v\",\n",
    "    'reco_nu_vtx_sce_[xyz]', 'trk_sce_start_[xyz]_v', 'trk_sce_end_[xyz]_v',\n",
    "    \"trk_mcs_muon_mom_v\",\"trk_range_muon_mom_v\", \"trk_len_v\",\n",
    "    'trk_llr_pid_score_v',\"pfp_generation_v\",\"trk_distance_v\",\"trk_theta_v\",\"trk_phi_v\",\n",
    "    #\"trk_energy_muon\",\"trk_energy_tot\",\"trk_energy\",\n",
    "    'trk_energy_muon_v','trk_energy_proton_v',\n",
    "]\n",
    "if USECRT:\n",
    "    variables.append('crtveto')\n",
    "    variables.append('_closestNuCosmicDist')\n",
    "    variables.append('crthitpe')\n",
    "MCVARS = [\"_opfilter_pe_beam\", \"_opfilter_pe_veto\",\n",
    "         'nproton','npion','npi0','nmuon','nu_e','ccnc','nu_pdg','theta',\n",
    "         'backtracked_pdg','category','interaction']\n",
    "WEIGHTS = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\"]\n",
    "if LOADDETSYS: WEIGHTS += [\"weightsGenie\", \"weightsFlux\"] #\"weightsReint\"\n",
    "\n",
    "#################################\n",
    "# create dataframes\n",
    "# preselection applied immediately (for memory reasons)\n",
    "print(\"starting to build dataframes at {}...\".format(moreFunctions.get_current_time(\"%H:%M:%S\")))\n",
    "query,_ = moreFunctions.get_NUMU_sel(False, opfilter=False) #no opfilter vars for first few\n",
    "for run in BNB: \n",
    "    DFs = [sample.pandas.df(variables, flatten=False).query(query) for sample in BNB[run]]\n",
    "    BNB[run] = pd.DataFrame().append(DFs, ignore_index=True)\n",
    "print(\"Data dfs built and appended {}..\".format(moreFunctions.get_current_time(\"%H:%M:%S\")))\n",
    "\n",
    "for run in EXT:\n",
    "    DFs = [sample.pandas.df(variables, flatten=False).query(query) for sample in EXT[run]]\n",
    "    EXT[run] = pd.DataFrame().append(DFs, ignore_index=True)\n",
    "print(\"EXT dfs built and appended {}...\".format(moreFunctions.get_current_time(\"%H:%M:%S\")))\n",
    "\n",
    "query,_ = moreFunctions.get_NUMU_sel(False, opfilter=True) #apply opfilter correction\n",
    "for run in MC:\n",
    "    DFs = [sample.pandas.df(variables + WEIGHTS + MCVARS, flatten=False).query(query) for sample in MC[run]]\n",
    "    MC[run] = pd.DataFrame().append(DFs, ignore_index=True)\n",
    "print(\"MC dfs built and appended {}...\".format(moreFunctions.get_current_time(\"%H:%M:%S\")))\n",
    "\n",
    "for run in DIRT:\n",
    "    print(run, DIRT.keys())\n",
    "    DFs = [sample.pandas.df(variables + WEIGHTS + MCVARS, flatten=False).query(query) for sample in DIRT[run]]\n",
    "    DIRT[run] = pd.DataFrame().append(DFs, ignore_index=True)\n",
    "print(\"Dirt dfs built and appended {}...\".format(moreFunctions.get_current_time(\"%H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize samples and weights for systematic manipulation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# organize things\n",
    "SAMPLES_RUN = {1: {}, 2: {}, 3: {}, 'combined': {}}\n",
    "for run in BNB: SAMPLES_RUN[run]['data'] = BNB[run]\n",
    "for run in EXT: SAMPLES_RUN[run]['ext'] = EXT[run]\n",
    "for run in MC: SAMPLES_RUN[run]['mc'] = MC[run]\n",
    "for run in DIRT: SAMPLES_RUN[run]['dirt'] = DIRT[run]\n",
    "#################################\n",
    "# Weights for each Run + combined\n",
    "# https://docs.google.com/spreadsheets/d/1vdcm3FoYIF1XiS6qx4qTCbaTH79vu-Sb5j8dnqctaTM/edit#gid=1344532859\n",
    "WEIGHTS_RUN = {\n",
    "    1: {\n",
    "        'ext': 4.96E-01,\n",
    "        'dirt': 4.50E-01,\n",
    "        'mc': 1.11E-01,\n",
    "        'nue': 1.11E-01,\n",
    "        'data': 1,\n",
    "        'pot': 1.45E+20,\n",
    "    },\n",
    "    2: {\n",
    "        'ext': 5.00E-01,\n",
    "        'dirt': 4.00E-01, #R1+R2\n",
    "        'mc': 2.55E-01,\n",
    "        'nue': 2.55E-01,\n",
    "        'data': 1,\n",
    "        'pot': 2.59E+20,\n",
    "    },\n",
    "    3: {\n",
    "        'ext': 0.435, #combined G1+G2\n",
    "        'dirt': 4.86E-01,\n",
    "        'mc': 1.18E-01,\n",
    "        'nue': 1.18E-01,\n",
    "        'data': 1,\n",
    "        'pot': 1.58E+20,\n",
    "    },\n",
    "    'combined': {\n",
    "        'ext': 5.0E-01,\n",
    "        'dirt': 9.12E-01,\n",
    "        'mc': 1.61E-01,\n",
    "        'nue': 1.61E-01,\n",
    "        'data': 1,\n",
    "        'pot': 5.9E+20,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_mu = 0.105 #GeV/c\n",
    "M_p = 0.938 #GeV/c\n",
    "M_n = 0.939 #GeV/c\n",
    "B = 0.04 #binding energy of argon used in simulation\n",
    "proton_pidscore = -0.2 #proton candidate < proton_pidscore\n",
    "\n",
    "for run in SAMPLES_RUN:\n",
    "    samples = SAMPLES_RUN[run]\n",
    "    #######################################\n",
    "    ## Calibrations\n",
    "    for i,df in enumerate([samples['mc'],samples['dirt']]):\n",
    "        df.loc[ df['weightTune'] <= 0, 'weightTune' ] = 1.\n",
    "        df.loc[ df['weightTune'] == np.inf, 'weightTune' ] = 1.\n",
    "        df.loc[ df['weightTune'] > 100, 'weightTune' ] = 1.\n",
    "        df.loc[ np.isnan(df['weightTune']) == True, 'weightTune' ] = 1.\n",
    "        df.loc[ df['weightSplineTimesTune'] <= 0, 'weightSplineTimesTune' ] = 1.\n",
    "        df.loc[ df['weightSplineTimesTune'] == np.inf, 'weightSplineTimesTune' ] = 1.\n",
    "        df.loc[ df['weightSplineTimesTune'] > 100, 'weightSplineTimesTune' ] = 1.\n",
    "        df.loc[ np.isnan(df['weightSplineTimesTune']) == True, 'weightSplineTimesTune' ] = 1.\n",
    "        #df['weightSpline']  = df['weightSpline']  * df['weightTune']\n",
    "        #df.loc[ df['npi0'] > 0, 'weightSplineTimesTune' ] = df['weightSpline'] * df['weightTune'] * 0.7 #scale down pi0s\n",
    "\n",
    "    if USECRT:\n",
    "        for sample in ['ext','data']:\n",
    "            df = samples[sample]\n",
    "            #only apply to data and ext\n",
    "            df.loc[(df['run'] > 16300),'crthitpe'] = df['crthitpe']*1.09 #hitpe correction\n",
    "    ##########################################\n",
    "    ## Calculated columns\n",
    "    for sample in samples:\n",
    "        df = samples[sample]\n",
    "        #useful variables\n",
    "        df[\"slclnhits\"] = df[\"pfnhits\"].apply(lambda x: sum(x))\n",
    "        df[\"slclnunhits\"] = df[\"pfnunhits\"].apply(lambda x: sum(x))\n",
    "        df['trk_p_quality_v'] = (df['trk_mcs_muon_mom_v']-df['trk_range_muon_mom_v'])/df['trk_range_muon_mom_v']\n",
    "        df['trk_cos_theta_v'] = df['trk_theta_v'].apply(lambda x: np.cos(x))\n",
    "        df['trk_sin_theta_v'] = df['trk_theta_v'].apply(lambda x: np.sin(x))\n",
    "        df['trk_cos_phi_v'] = df['trk_phi_v'].apply(lambda x: np.cos(x))\n",
    "        df['trk_sin_phi_v'] = df['trk_phi_v'].apply(lambda x: np.sin(x))\n",
    "        df['trk_range_proton_mom_v'] = df['trk_energy_proton_v'].apply(lambda x: np.sqrt(2*M_p*x))\n",
    "        df['trk_range_muon_e_v'] = (df['trk_range_muon_mom_v']**2 + M_mu**2)**.5 # E\n",
    "        df['trk_range_muon_ke_v'] = df['trk_range_muon_e_v'] - M_mu #KE\n",
    "        df['trk_energy_tot'] = df[\"trk_energy_proton_v\"].apply(lambda x: sum(x)) #is missing from G1 sample\n",
    "        df['reco_nu_e_range_v'] = df[\"trk_range_muon_e_v\"] + (df[\"trk_energy_tot\"] - df[\"trk_energy_proton_v\"])     \n",
    "        #df['reco_nproton'] = df['trk_llr_pid_score_v'].apply(lambda x: len(x[x<proton_pidscore]) + 0.01) #add the 0.1 to prevent issue later\n",
    "        #protons have trk_score cut and llr_pid_score cut\n",
    "        proton_mask = df['trk_score_v'].apply(lambda x: x>0.5) * df['trk_llr_pid_score_v'].apply(lambda x: x<proton_pidscore)\n",
    "        df['reco_nproton'] = (df['trk_llr_pid_score_v']*proton_mask).apply(lambda x: len(x[x!=False]))\n",
    "        df['reco_ntrack'] = df['trk_score_v'].apply(lambda x: len(x))\n",
    "        # break momentum vector apart\n",
    "        df['trk_dx_v'] = df['trk_sin_theta_v']*df['trk_cos_phi_v']\n",
    "        df['trk_dy_v'] = df['trk_sin_theta_v']*df['trk_sin_phi_v']\n",
    "        df['trk_dz_v'] = df['trk_cos_theta_v']\n",
    "\n",
    "        #just MC stuff (truth level)\n",
    "        if sample in [\"mc\",\"dirt\"]:\n",
    "            df['backtracked_pdg_v'] = df['backtracked_pdg']\n",
    "    \n",
    "    ########################################################\n",
    "    # add back the cosmic category\n",
    "    # and calculate Nproton multiplicity if you so desire\n",
    "    df = samples['mc']\n",
    "    df.loc[(df['category']!=1)&(df['category']!=10)&(df['category']!=11)&(df['category']!=111)&\n",
    "           (df['slnunhits']/df['slnhits'] < 0.2), 'category'] = 4\n",
    "    if NPROTON_CAT:\n",
    "        df.loc[(df['category']==2)&(df['nproton']==0), 'category'] = 22\n",
    "        df.loc[(df['category']==2)&(df['nproton']==1), 'category'] = 23\n",
    "        df.loc[(df['category']==2)&(df['nproton']==2), 'category'] = 24\n",
    "        df.loc[(df['category']==2)&(df['nproton']>=3), 'category'] = 25\n",
    "\n",
    "    samples['nue'] = samples['mc'].query('nu_pdg == 12 or nu_pdg == -12')\n",
    "    samples['mc']  = samples['mc'].query('nu_pdg == 14 or nu_pdg == -14')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginning of analysis section\n",
    "### Preselect dataframes, this is a time saver\n",
    "### Can also use plotter function to apply selection, waste of time, some potential bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(moreFunctions)\n",
    "CONTAINED = True\n",
    "CONTAINEDHIGHE = True #both contained and above\n",
    "\n",
    "fullsel_SAMPLES_RUN = {}\n",
    "for run in SAMPLES_RUN:\n",
    "    print(\"Run {}: {}\".format(run, moreFunctions.get_current_time(\"%H:%M:%S\")))\n",
    "    samples = SAMPLES_RUN[run]\n",
    "    fullsel_SAMPLES_RUN[run] = {}\n",
    "    for sample in samples:\n",
    "        print(\"{}: {}\".format(sample, moreFunctions.get_current_time(\"%H:%M:%S\")))\n",
    "        fullsel_SAMPLES_RUN[run][sample] = moreFunctions.apply_muon_fullsel(samples[sample], sample, False, LOADDETSYS)\n",
    "        \n",
    "if CONTAINED:\n",
    "    fullsel_contained_SAMPLES_RUN = {}\n",
    "    for run in SAMPLES_RUN:\n",
    "        print(\"Run {}: {}\".format(run, moreFunctions.get_current_time(\"%H:%M:%S\")))\n",
    "        fullsel_contained_SAMPLES_RUN[run] = {}\n",
    "        samples = SAMPLES_RUN[run]\n",
    "        for sample in samples:\n",
    "            print(\"{}: {}\".format(sample, moreFunctions.get_current_time(\"%H:%M:%S\")))\n",
    "            #get all the fullsel events, with all the tracks, not just muon candidates\n",
    "            df = SAMPLES_RUN[run][sample].loc[fullsel_SAMPLES_RUN[run][sample].index]\n",
    "            #then apply the containment filter\n",
    "            fullsel_contained_SAMPLES_RUN[run][sample] = moreFunctions.apply_contained(df, sample, False, LOADDETSYS)\n",
    "            \n",
    "    if CONTAINEDHIGHE:\n",
    "        fullsel_contained_above105_SAMPLES_RUN = {}\n",
    "        for run in SAMPLES_RUN:\n",
    "            print(\"Run {}: {}\".format(run, moreFunctions.get_current_time(\"%H:%M:%S\")))\n",
    "            fullsel_contained_above105_SAMPLES_RUN[run] = {}\n",
    "            samples = fullsel_contained_SAMPLES_RUN[run]\n",
    "            for sample in samples:\n",
    "                print(\"{}: {}\".format(sample, moreFunctions.get_current_time(\"%H:%M:%S\")))\n",
    "                fullsel_contained_above105_SAMPLES_RUN[run][sample] = moreFunctions.apply_contained(df, sample, False, LOADDETSYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of contained reco tracks for whatever _SAMPLES_RUN preselected thing\n",
    "DFs = fullsel_contained_SAMPLES_RUN\n",
    "for run in DFs:\n",
    "    samples = DFs[run]\n",
    "    for sample in samples:\n",
    "        df['reco_contained_ntrack'] = samples[sample]['trk_score_v'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pamv0W8YJ9R"
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# CCQE STUFF\n",
    "# This takes a while, but you get a bunch of CCQE dataframes\n",
    "importlib.reload(moreFunctions)\n",
    "CCQE_presel_samples = {}\n",
    "CCQE_muon_samples = {}\n",
    "CCQE_proton_samples = {}\n",
    "CCQE_samples = {}\n",
    "verbose = False\n",
    "\n",
    "for run in SAMPLES_RUN:\n",
    "    print(\"Run {}: {}\".format(run, moreFunctions.get_current_time(\"%H:%M:%S\")))\n",
    "    samples = SAMPLES_RUN[run]\n",
    "    CCQE_presel_samples[run] = {}\n",
    "    CCQE_muon_samples[run] = {}\n",
    "    CCQE_proton_samples[run] = {}\n",
    "    CCQE_samples[run] = {}\n",
    "    for sample in samples:\n",
    "        print(\"{}: {}\".format(sample, moreFunctions.get_current_time(\"%H:%M:%S\")))\n",
    "        #events that have atleast one muon candidate and exactly 2 reco tracks\n",
    "        if verbose: print(\"presel...\")\n",
    "        CCQE_presel_samples[run][sample] = moreFunctions.apply_CCQE_presel(samples[sample], sample, False, LOADDETSYS)\n",
    "        if verbose: print(\"muons...\")\n",
    "        CCQE_muon_samples[run][sample] = moreFunctions.select_muons(CCQE_presel_samples[run][sample], sample, False, LOADDETSYS)\n",
    "        if verbose: print(\"protons...\")\n",
    "        CCQE_proton_samples[run][sample] = moreFunctions.select_protons(CCQE_presel_samples[run][sample], sample, False, LOADDETSYS)\n",
    "        if verbose: print(\"done\")\n",
    "        #intersection of muon & proton dataframes are the 1mu1p events\n",
    "        muon_entries = set(CCQE_muon_samples[run][sample].index)\n",
    "        proton_entries = set(CCQE_proton_samples[run][sample].index)\n",
    "        intersec = list(muon_entries & proton_entries)\n",
    "        #update everything\n",
    "        CCQE_samples[run][sample] = CCQE_presel_samples[run][sample].loc[intersec]\n",
    "        CCQE_muon_samples[run][sample] = CCQE_muon_samples[run][sample].loc[intersec]\n",
    "        CCQE_proton_samples[run][sample] = CCQE_proton_samples[run][sample].loc[intersec]\n",
    "        #make sure this is fixed\n",
    "        \n",
    "########################################\n",
    "#make the CCQE calculated variables\n",
    "M_mu = 0.105 #GeV/c\n",
    "M_p = 0.938 #GeV/c\n",
    "M_n = 0.939 #GeV/c\n",
    "B = 0.04 #binding energy of argon used in simulation\n",
    "\n",
    "for run in CCQE_samples:\n",
    "    for sample in CCQE_samples[run]:\n",
    "        df = CCQE_samples[run][sample]\n",
    "        df_muon = CCQE_muon_samples[run][sample]\n",
    "        df_proton = CCQE_proton_samples[run][sample]\n",
    "        ########\n",
    "        df_muon['p'] = df_muon['trk_range_muon_mom_v']\n",
    "        df_muon['E'] = df_muon['trk_range_muon_e_v']\n",
    "        df_muon['px'] = df_muon['p']*df_muon['trk_dx_v']\n",
    "        df_muon['py'] = df_muon['p']*df_muon['trk_dy_v']\n",
    "        df_muon['pz'] = df_muon['p']*df_muon['trk_dz_v']\n",
    "        df_muon['pT'] = (df_muon['px']**2 + df_muon['py']**2)**0.5\n",
    "        df_muon['pTransverseRatio'] = df_muon['pT'] / df_muon['p']\n",
    "        df_muon['trk_len'] = df_muon['trk_len_v'].apply(lambda x: x[0])\n",
    "        ########\n",
    "        df_proton['p'] = df_proton['trk_range_proton_mom_v']\n",
    "        df_proton['E'] = df_proton['trk_energy_proton_v']\n",
    "        df_proton['px'] = df_proton['p']*df_proton['trk_dx_v']\n",
    "        df_proton['py'] = df_proton['p']*df_proton['trk_dy_v']\n",
    "        df_proton['pz'] = df_proton['p']*df_proton['trk_dz_v']\n",
    "        df_proton['pT'] = (df_proton['px']**2 + df_proton['py']**2)**0.5\n",
    "        df_proton['pTransverseRatio'] = df_proton['pT'] / df_proton['p']\n",
    "        df_proton['trk_len'] = df_proton['trk_len_v'].apply(lambda x: x[0])\n",
    "        #########\n",
    "        df['Q2'] = 2 * df_muon['reco_nu_e_range_v'] * (df_muon['trk_range_muon_e_v'] - df_muon['p']**2) - M_mu**2\n",
    "        df['Mhad'] = df_muon['reco_nu_e_range_v'] - df_muon['trk_range_muon_e_v']\n",
    "        df['Xbj'] = df['Q2'] / (2 * M_n * df['Mhad'])\n",
    "        df['Ybj'] = df['Mhad'] / df_muon['reco_nu_e_range_v']\n",
    "        df['pT'] = ((df_muon['px'] + df_proton['px'])**2 + (df_muon['py'] + df_proton['py'])**2)**0.5\n",
    "        df['p'] = ((df_muon['px'] + df_proton['px'])**2 + (df_muon['py'] + df_proton['py'])**2 + (df_muon['pz'] + df_proton['pz'])**2)**0.5\n",
    "        df['pL'] = df_proton['pz']**2 + df_muon['pz']**2\n",
    "        df['pTransverseRatio'] = df['pT'] / df['p']\n",
    "        #opening angle\n",
    "        # cos(opening angle) = dot(muon unit vector, proton unit vector)\n",
    "        df['cos_alpha'] = df_muon['trk_dx_v']*df_proton['trk_dx_v'] + df_muon['trk_dy_v']*df_proton['trk_dy_v'] + df_muon['trk_dz_v']*df_proton['trk_dz_v']\n",
    "        df['opening_angle'] = df['cos_alpha'].apply(lambda x: np.arccos(x))\n",
    "        df['phi_diff'] = df_muon['trk_phi_v'] - df_proton['trk_phi_v']\n",
    "        df['theta_tot'] = df_muon['trk_theta_v'] + df_proton['trk_theta_v']\n",
    "        longest_mask = df['trk_len_v'].apply(lambda x: x == x[list(x).index(max(x))])#identify longest\n",
    "        df['trk_len'] = (df['trk_len_v']*longest_mask).apply(lambda x: x[x!=False]) #longest available track        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "## plot distributions of just one sample at a time\n",
    "## unweighted\n",
    "## doodles\n",
    "############################################\n",
    "SAMPLES = fullsel_samples\n",
    "counter = {}\n",
    "for run in SAMPLES:\n",
    "    samples = SAMPLES[run]\n",
    "    ext = samples['data']\n",
    "    counter[run] = ext.shape[0]\n",
    "counter['SumR'] = counter[1] + counter[2] + counter[3]\n",
    "for key in counter:\n",
    "    print(\"Run {}: {} bare entries\".format(key,counter[key]))\n",
    "\n",
    "\n",
    "'''\n",
    "VARIABLE, BINS, RANGE, XTIT = 'topological_score',25,(0,1),'Topological Score'\n",
    "SAMPLES = fullsel_samples\n",
    "SCALINGS = {\n",
    "    1: 64672423.0,\n",
    "    2: 122320769.0,\n",
    "    3: 86991453.0,\n",
    "    'combined': (646672423.0 + 122320769.0 + 86991453.0)\n",
    "}\n",
    "\n",
    "for run in SAMPLES:\n",
    "    if run == 'combined': continue\n",
    "    ext = SAMPLES[run]['ext']\n",
    "    plt.hist(\n",
    "        #ext[VARIABLE]*WEIGHTS_RUN[run]['ext'],\n",
    "        ext[VARIABLE],\n",
    "        weights = np.ones(ext[VARIABLE].shape[0])/SCALINGS[run],\n",
    "        bins = np.linspace(RANGE[0],RANGE[1],BINS+1),\n",
    "        label = r'EXT, Run {}'.format(run),\n",
    "        histtype='step',\n",
    "    )\n",
    "plt.xlabel('Topological Score')\n",
    "plt.title(r\"Full $\\nu_{\\mu}$ INC, Trigger Normalized\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(ls.plots_path+\"All-Open\\\\unweightedEXT_timedep_052120_trigNorm.pdf\")\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in fullsel_contained_above105_samples:\n",
    "    for sample in fullsel_contained_above105_samples[run]:\n",
    "        df = fullsel_contained_above105_samples[run][sample]\n",
    "        df['reco_ntrack_contained'] = df['trk_score_v'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "## Time-Dependent Studies\n",
    "## WORKHORSE NOTEBOOK\n",
    "## Make a plot for each run, then combined\n",
    "## need to upgrade to make one figure with all plots on it\n",
    "############################################\n",
    "importlib.reload(moreFunctions)\n",
    "\n",
    "#active volume\n",
    "AVx = [-1.55,254.8]\n",
    "AVy = [-115.53, 117.47]\n",
    "AVz = [0.1, 1036.9]\n",
    "\n",
    "VARIABLE, BINS, RANGE, XTIT = 'reco_ntrack',5,(0.5,5.5),r'Reco Track Multiplicity'\n",
    "VARIABLE, BINS, RANGE, XTIT = 'trk_cos_theta_v',24,(-1,1),r'Cos($\\theta$)'\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'topological_score',25,(0,1),'Topological Score'\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'run',50,(5000,17000),'Run'\n",
    "\n",
    "VARIABLES, BIN, RANGES, XTITS = [VARIABLE], [BINS], [RANGE], [XTIT]\n",
    "VARIABLES, BIN, RANGES, XTITS = moreFunctions.get_plots('CCQE') #look in NUMUhelper.py\n",
    "#VARIABLES, BIN, RANGES, XTITS = moreFunctions.get_plots('CCQE_proton_kinematics') \n",
    "#VARIABLES, BIN, RANGES, XTITS = moreFunctions.get_plots('CCQE_muon_kinematics')\n",
    "\n",
    "\n",
    "tag = \"fullsel_samples\" #this will show up in the name of saved figure\n",
    "SAMPLES = fullsel_samples #or SAMPLES_RUN, or fullsel_SAMPLES_RUN, CCQE_muon_samples, CCQE_proton_samples\n",
    "#plot_title = \"CCQE muon\"\n",
    "\n",
    "SAVEFIG = True\n",
    "DRAWDATA = True\n",
    "DRAWRATIO = True\n",
    "SELECTLONGEST = True\n",
    "DRAWSYS = False #need to load extra files\n",
    "\n",
    "SAVEDIR = ls.plots_path+\"All-Open\\\\\"\n",
    "if not os.path.exists(SAVEDIR): os.makedirs(SAVEDIR)\n",
    "\n",
    "QUERY, track_cuts = 'nslice == 1', None\n",
    "\n",
    "KIND = 'event_category'#interaction, backtracked_pdg, event_category\n",
    "\n",
    "if SELECTLONGEST: tag += '_longest'\n",
    "else: tag += '_alltracks'\n",
    "if not DRAWDATA: tag += \"_nodata\"\n",
    "if DRAWSYS: tag += '_detsys'\n",
    "\n",
    "if SAVEFIG:\n",
    "    pdf_large = matplotlib.backends.backend_pdf.PdfPages(SAVEDIR+\"timeDep_combined_{}_{}.pdf\".format(date_time,tag)) #pdf of everything made this batch\n",
    "for (VARIABLE, BINS, RANGE, XTIT) in zip(VARIABLES, BIN, RANGES, XTITS):\n",
    "#####################################################################\n",
    "#get specific cuts based on what the tag is\n",
    "#QUERY, track_cuts = moreFunctions.get_Cuts(tag, ISRUN3)\n",
    "    if SAVEFIG:\n",
    "        pdf = matplotlib.backends.backend_pdf.PdfPages(SAVEDIR+\"timeDep_combined_{}_{}_{}_{}.pdf\".format(VARIABLE,date_time,tag,KIND)) #pdf of variable groupings\n",
    "\n",
    "    for run in SAMPLES:\n",
    "        print(run)\n",
    "        plot_sample = SAMPLES[run]\n",
    "        weights = WEIGHTS_RUN[run]\n",
    "        pot = WEIGHTS_RUN[run]['pot']\n",
    "        plot_title = \"Fullsel, Contained, muon, R {}\".format(run)\n",
    "        #######################################################\n",
    "        # plotting\n",
    "        my_plotter = plotter.Plotter(plot_sample, weights, pot=pot)\n",
    "        fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "            VARIABLE,   \n",
    "            query=QUERY,\n",
    "            kind=KIND, #sample, interaction, backtracked_pdg\n",
    "            track_cuts = track_cuts,\n",
    "            select_longest = SELECTLONGEST, #this is true by default in self._selection\n",
    "            title=XTIT,\n",
    "            #bins=asymm_bins,\n",
    "            bins=BINS,\n",
    "            stacksort=4, #0-numerical, 1-weights, 2-eLee on top, 3-eLee+nue on top, 4-numu on top\n",
    "            range=RANGE,\n",
    "            ratio=DRAWRATIO,\n",
    "            draw_sys=DRAWSYS,\n",
    "            purity=False,\n",
    "            draw_data=DRAWDATA,\n",
    "        )[0:3]\n",
    "        print(\"Profile likelihood: {} sigma @ {} POT\".format(my_plotter.significance_likelihood,pot))\n",
    "        print(\"s/sqrt(b): {} sigma @ {} POT\".format(my_plotter.significance, pot))\n",
    "\n",
    "        #ax1.set_ylim(0,40)\n",
    "        #ax1.set_yscale(\"log\")\n",
    "        #ax1.set_ylim(0,3000)\n",
    "        ax1.set_ylim(0,ax1.get_ylim()[1]*1.5)\n",
    "        ax2.set_ylim(0.5,1.5)\n",
    "        ax1.set_title(plot_title, fontsize=20)\n",
    "\n",
    "        if SAVEFIG:\n",
    "            fn = VARIABLE+\"_\"+date_time+\"_\"+tag+'_'+KIND\n",
    "            fn += \".pdf\"\n",
    "            print(\"saving to {}...\".format(\"{}\\\\{}\\\\{}\".format(SAVEDIR,run,fn)))\n",
    "            fig.tight_layout()\n",
    "            if not os.path.exists(SAVEDIR+str(run)): os.makedirs(SAVEDIR+str(run))\n",
    "            fig.savefig(\"{}{}\\\\{}\".format(SAVEDIR,run,fn))\n",
    "            pdf.savefig(fig)\n",
    "            pdf_large.savefig(fig)\n",
    "        plt.show()\n",
    "\n",
    "if SAVEFIG: \n",
    "    pdf.close()\n",
    "    pdf_large.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2342,
     "status": "ok",
     "timestamp": 1560557343774,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "b93hN-pGYJ9T",
    "outputId": "17e7c7ed-3f12-4b03-805c-6698f1617878"
   },
   "outputs": [],
   "source": [
    "############################################\n",
    "## Generic plot maker with all the fixins\n",
    "############################################\n",
    "importlib.reload(moreFunctions)\n",
    "\n",
    "#active volume\n",
    "AVx = [-1.55,254.8]\n",
    "AVy = [-115.53, 117.47]\n",
    "AVz = [0.1, 1036.9]\n",
    "\n",
    "VARIABLE, BINS, RANGE, XTIT = 'nu_e',14,(0.15,1.55),r'True $\\nu$ Energy [GeV]'\n",
    "VARIABLE, BINS, RANGE, XTIT = 'reco_nproton',5,(-0.5,4.5),r'Reco Proton Multiplicity'\n",
    "VARIABLE, BINS, RANGE, XTIT = 'reco_ntracks',5,(0.5,5.5),r'Reco Track Multiplicity'\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'reco_contained_ntrack',5,(0.5,5.5),r'Reco Contained Track Multiplicity'\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'nproton',5,(-0.5,4.5),r'True Proton Multiplicity'\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'reco_nu_e_range_v',14,(0.15,1.55),r'Reco Range-Based $\\nu$ Energy [GeV]'\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'trk_len_v',24,(0,100),r'Track Length [cm]'\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'trk_score_v',24,(0.5,1),r'Track Score'\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'trk_distance_v',24,(0,10),r'Track Distance [cm]'\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'trk_p_quality_v',24,(-1,2.5),r'MCS Consistency $(\\frac{P_{MCS}-P_{Range}}{P_{Range}})$'\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'crtveto',2,(-0.5,1.5),r'CRT Veto'\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'crthitpe', 25, (0.1,600), \"CRT hit PE\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'trk_llr_pid_score_v', 25, (-1, 1), \"LLR PID Score\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'Q2_v', 25, (0,2), \"Q2\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'Mhad_v', 25, (0,2.5), r\"M$_{hadron}$\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'Xbj_v', 25, (0,3), r\"Bjorken x\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'Ybj_v', 25, (0,2), r\"Bjorken y\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'trk_cos_theta_v',24,(-1,1),r'Cos($\\theta$)'\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'trk_energy_proton_v', 25, (0,1), r'Reco Range-Based Proton Energy [GeV]'\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'trk_range_muon_e_v', 25, (0,1.5), r'Reco Range-Based Muon Energy [GeV]'\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'NeutrinoEnergy2', 25, (0,2000), 'Visible Energy on Plane 2 [MeV]'\n",
    "\n",
    "VARIABLES, BIN, RANGES, XTITS = [VARIABLE], [BINS], [RANGE], [XTIT]\n",
    "VARIABLES, BIN, RANGES, XTITS = moreFunctions.get_plots('CCQE')\n",
    "#VARIABLES, BIN, RANGES, XTITS = moreFunctions.get_plots('CCQE_proton_kinematics')\n",
    "#VARIABLES, BIN, RANGES, XTITS = moreFunctions.get_plots('CCQE_muon_kinematics')\n",
    "\n",
    "#tag gets added to end of .pdf name and changes some parameters\n",
    "#for example if \"presel\" is in the tag, no track_cuts will be applied\n",
    "#include category, sample, interaction, or backtracked_pdg in tag to change category (default \"category\")\n",
    "# \"above105\" or \"below105\" in tag make cuts on reco neutrino energy (1.05 GeV is muon mass E)\n",
    "#tag = \"presel_contained_samples_pdg_alltracks\"\n",
    "tag = \"fullsel_contained_above105_samples_allopen\"\n",
    "SAVEFIG = True\n",
    "DRAWDATA = True\n",
    "DRAWRATIO = True\n",
    "SELECTLONGEST = True\n",
    "DRAWSYS = False #need to load extra files\n",
    "#If plot_sample is fullsel_samples, change tag to \"fullsel_samples to save time ;)\n",
    "#SAVEDIR = ls.plots_path+\"Run3\\\\\"+ls.SAMPLE+\"\\\\aprilcm-response\\\\\"\n",
    "SAVEDIR = ls.plots_path+\"All-Open\\\\\"\n",
    "if not os.path.exists(SAVEDIR): os.makedirs(SAVEDIR)\n",
    "QUERY, track_cuts = 'nslice == 1', None\n",
    "KINDS = ['event_category','interaction'] #interaction, backtracked_pdg, event_category\n",
    "#KINDS = ['event_category']\n",
    "\n",
    "if SELECTLONGEST:\n",
    "    tag += '_longest'\n",
    "else:\n",
    "    tag += '_alltracks'\n",
    "if not DRAWDATA:\n",
    "    tag += \"_nodata\"\n",
    "if DRAWSYS:\n",
    "    tag += '_detsys'\n",
    "\n",
    "#if 23 in np.array(plot_sample['mc']['category']): \n",
    "#    tag += '_nproton'\n",
    "\n",
    "for KIND in KINDS:\n",
    "    if len(VARIABLES) > 1:\n",
    "        pdf = matplotlib.backends.backend_pdf.PdfPages(SAVEDIR+\"combined_{}_{}_{}.pdf\".format(date_time,tag,KIND))\n",
    "    for (VARIABLE, BINS, RANGE, XTIT) in zip(VARIABLES, BIN, RANGES, XTITS):\n",
    "    #####################################################################\n",
    "        # lots of formatting things based on the tag\n",
    "        fullsel_contained_above105_samples\n",
    "        if \"fullsel_contained_above105_samples\" in tag.lower():\n",
    "            print(\"using fullsel_contained_above105_samples\")\n",
    "            plot_sample = fullsel_contained_above105_samples #or samples, or presel_sapmles, \n",
    "            plot_title = r\"Fullsel INC (E$^{reco}_{\\nu}$ > 1.05 GeV), contained,\"\n",
    "        elif \"fullsel_above105_samples\" in tag.lower():\n",
    "            print(\"using fullsel_above105_samples\")\n",
    "            plot_sample = fullsel_above105_samples #or samples, or presel_sapmles, \n",
    "            plot_title = r\"Fullsel INC (E$^{reco}_{\\nu}$ > 1.05 GeV)\"\n",
    "        elif \"fullsel_contained_samples\" in tag.lower():\n",
    "            print(\"using presel_contained_samples\")\n",
    "            plot_sample = fullsel_contained_samples\n",
    "            plot_title = \"Fullsel, Contained Tracks, \"\n",
    "        elif \"fullsel_sample\" in tag.lower():\n",
    "            print(\"using fullsel_muon_samples\")\n",
    "            plot_sample = fullsel_samples #or samples, or presel_sapmles, \n",
    "            plot_title = \"Fullsel INC\"\n",
    "        elif \"ccqe_muon\" in tag.lower():\n",
    "            print(\"using CCQE_muon_samples\")\n",
    "            plot_sample = CCQE_muon_samples \n",
    "            plot_title = \"CCQE muon\"\n",
    "        elif \"ccqe_proton\" in tag.lower():\n",
    "            print(\"using CCQE_proton_samples\")\n",
    "            plot_sample = CCQE_proton_samples \n",
    "            plot_title = \"CCQE proton\"\n",
    "        elif \"ccqe_contained\" in tag.lower():\n",
    "            plot_sample = CCQE_contained_samples \n",
    "            plot_title = \"CCQE, contained tracks\"\n",
    "        elif \"ccqe_sample\" in tag.lower():\n",
    "            plot_sample = CCQE_samples \n",
    "            plot_title = \"CCQE\"\n",
    "        elif \"fullsel_nomcs_sample\" in tag.lower():\n",
    "            print(\"using fullsel_noMCS_muon_samples\")\n",
    "            plot_sample = fullsel_noMCS_samples \n",
    "            plot_title = \"Fullsel, No MCS Cut, \"\n",
    "        elif \"ccqe_tracktester_contained\" in tag.lower():\n",
    "            plot_sample = CCQE_tracktester_contained_samples\n",
    "            plot_title = \"CCQE, trk_score > 0.5, contained\"\n",
    "        elif \"ccqe_tracktester\" in tag.lower():\n",
    "            plot_sample = CCQE_tracktester_samples\n",
    "            plot_title = \"CCQE, trk_score > 0.5\"\n",
    "        elif \"presel_sample\" in tag.lower():\n",
    "            plot_sample = presel_samples\n",
    "            plot_title = \"Presel\"\n",
    "        elif \"samples\" in tag.lower():\n",
    "            plot_sample = samples\n",
    "            if \"presel\" in ls.SAMPLE:\n",
    "                plot_title = \"Presel\"\n",
    "            else:\n",
    "                plot_title = \"NoSel\"\n",
    "        else:\n",
    "            print(\"using default samples\")\n",
    "            plot_sample = samples\n",
    "            if \"presel\" in ls.SAMPLE:\n",
    "                plot_title = \"Presel\"\n",
    "            else:\n",
    "                plot_title = \"NoSel\"\n",
    "\n",
    "        if not SELECTLONGEST:\n",
    "            plot_title += ', all tracks'\n",
    "        if \"noopfilter\" in tag.lower():\n",
    "            plot_title += ', no opfilter cuts'\n",
    "\n",
    "        if VARIABLE not in samples['data'].keys(): samples['data'][VARIABLE] = -999\n",
    "\n",
    "        if \"above105\" in tag.lower():\n",
    "            XTIT += \" (reco_nu_e_range > 1.05 GeV)\"\n",
    "        elif \"below105\" in tag.lower():\n",
    "            XTIT += \" (reco_nu_e_range <= 1.05 GeV)\"\n",
    "            if VARIABLE == 'reco_nu_e_range_v':\n",
    "                BINS,  RANGE = 11, (-0.05, 1.05)\n",
    "\n",
    "        if \"fullsel_samples\" in tag.lower():\n",
    "            plot_sample = fullsel_samples\n",
    "        elif \"fullsel_notopo_samples\" in tag.lower():\n",
    "            plot_sample = fullsel_notopo_samples\n",
    "\n",
    "        if \"nomcs\" in tag.lower():\n",
    "            XTIT += \" no MCS cut\"\n",
    "        elif \"invertmcs\" in tag.lower():\n",
    "            XTIT += ' inverted MCS cut'\n",
    "\n",
    "        if \"true2212\" in tag.lower():\n",
    "            XTIT += ' (true leading proton) '\n",
    "\n",
    "        if 'crtgt100' in tag.lower():\n",
    "            XTIT += ' (crthitpe > 100)'\n",
    "        elif 'crtlt100' in tag.lower():\n",
    "            XTIT += ' (crthitpe < 100)'\n",
    "        elif 'invertcrt' in tag.lower():\n",
    "            XTIT += ' (crthitpe > 100 and crtveto == 0)'\n",
    "\n",
    "\n",
    "        #get specific cuts based on what the tag is\n",
    "        #QUERY, track_cuts = moreFunctions.get_Cuts(tag, ISRUN3)\n",
    "        #######################################################\n",
    "        # plotting\n",
    "        print(tag)\n",
    "        my_plotter = plotter.Plotter(plot_sample, weights, pot=pot)\n",
    "        fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "            VARIABLE,   \n",
    "            query=QUERY,\n",
    "            kind=KIND, #sample, interaction, backtracked_pdg\n",
    "            track_cuts = track_cuts,\n",
    "            select_longest = SELECTLONGEST, #this is true by default in self._selection\n",
    "            title=XTIT,\n",
    "            #bins=asymm_bins,\n",
    "            bins=BINS,\n",
    "            stacksort=4, #0-numerical, 1-weights, 2-eLee on top, 3-eLee+nue on top, 4-numu on top\n",
    "            range=RANGE,\n",
    "            ratio=DRAWRATIO,\n",
    "            draw_sys=DRAWSYS,\n",
    "            purity=False,\n",
    "            draw_data=DRAWDATA,\n",
    "        )[0:3]\n",
    "        print(\"Profile likelihood: {} sigma @ {} POT\".format(my_plotter.significance_likelihood,pot))\n",
    "        print(\"s/sqrt(b): {} sigma @ {} POT\".format(my_plotter.significance, pot))\n",
    "\n",
    "        #ax1.set_ylim(0,40)\n",
    "        #ax1.set_yscale(\"log\")\n",
    "        #ax1.set_ylim(0,12000)\n",
    "        ax1.set_ylim(0,ax1.get_ylim()[1]*1.5)\n",
    "        ax2.set_ylim(0.5,1.5)\n",
    "        ax1.set_title(plot_title, fontsize=20)\n",
    "\n",
    "        if SAVEFIG:\n",
    "            fn = VARIABLE+\"_\"+date_time+\"_\"+tag+'_'+KIND\n",
    "            fn += \".pdf\"\n",
    "            print(\"saving to {}...\".format(SAVEDIR+fn))\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(SAVEDIR+fn)\n",
    "            if len(VARIABLES) > 1:\n",
    "                pdf.savefig(fig)\n",
    "        plt.show()\n",
    "        \n",
    "    if SAVEFIG and len(VARIABLES) > 1:\n",
    "        pdf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
